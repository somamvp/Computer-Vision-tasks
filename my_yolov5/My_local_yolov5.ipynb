{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Jupyter-notebook for Local machine, GTX3090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soma2/MVP\n",
      "/home/soma2/MVP/voyager-Vision-task\n",
      "Ïù¥ÎØ∏ ÏóÖÎç∞Ïù¥Ìä∏ ÏÉÅÌÉúÏûÖÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/soma2/MVP\n",
    "# !git clone https://github.com/biancco/SOMA-vision-task.git  # clone\n",
    "\n",
    "%cd voyager-Vision-task\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soma2/MVP/voyager-Vision-task/my_yolov5\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu110 in /home/soma4/.local/lib/python3.8/site-packages (1.7.1+cu110)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu110 in /home/soma4/.local/lib/python3.8/site-packages (0.8.2+cu110)\n",
      "Requirement already satisfied: numpy in /home/soma4/.local/lib/python3.8/site-packages (from torch==1.7.1+cu110) (1.23.1)\n",
      "Requirement already satisfied: typing-extensions in /home/soma4/.local/lib/python3.8/site-packages (from torch==1.7.1+cu110) (4.3.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/soma4/.local/lib/python3.8/site-packages (from torchvision==0.8.2+cu110) (9.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "%pip install -qr requirements_local.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "5e22f100-fe2e-4390-dfee-cc019821be25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ 2215c1f Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ‚úÖ (16 CPUs, 62.7 GB RAM, 672.0/937.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 1. Train\n",
    "Train \\*.pt through \"train.py\" python script with options<br>\n",
    "```shell\n",
    "    --cfg  model.yaml\n",
    "    --weight  yolov5s.pt\n",
    "    --img  640\n",
    "    --batch  16\n",
    "    --epochs  10\n",
    "    --data  data.yaml\n",
    "    --save-period  1\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=parse_1.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "https://github.com/somamvp/voyager-Vision-tasks URLÏóêÏÑú\n",
      " * [ÏÉàÎ°úÏö¥ Î∏åÎûúÏπò]   parser-3   -> origin/parser-3\n",
      "fatal: Ïï†Îß§Ìïú Ïù∏Ïûê 'main..origin/master': Ïïå Ïàò ÏóÜÎäî Î¶¨ÎπÑÏ†Ñ ÎòêÎäî ÏûëÏóÖ Ìè¥ÎçîÏóê ÏóÜÎäî Í≤ΩÎ°ú.\n",
      "Í≤ΩÎ°úÏôÄ Î¶¨ÎπÑÏ†ÑÏùÑ Íµ¨Î∂ÑÌïòÎ†§Î©¥ Îã§ÏùåÍ≥º Í∞ôÏù¥ '--'Î•º ÏÇ¨Ïö©ÌïòÏã≠ÏãúÏò§:\n",
      "'git <Î™ÖÎ†π> [<Î¶¨ÎπÑÏ†Ñ>...] -- [<ÌååÏùº>...]'\n",
      "Command 'git rev-list main..origin/master --count' returned non-zero exit status 128.\n",
      "YOLOv5 üöÄ b41502d Python-3.7.2 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=27\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     86304  models.yolo.Detect                      [27, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7092448 parameters, 7092448 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma2/MVP/Aihub/parse_1/train/labels' images and labels..\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_000231.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_001512.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_005259.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_007214.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_008382.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_008657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_010268.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_011766.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_017485.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parse_1/train/images/MP_SEL_018950.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/soma2/MVP/Aihub/parse_1/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma2/MVP/Aihub/parse_1/val/labels' images and labels...217\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/soma2/MVP/Aihub/parse_1/val/labels.cache\n",
      "Plotting labels to runs/train/exp3/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.81 anchors/target, 0.957 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 2183 of 190258 labels are < 3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 190256 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6951: 100%|‚ñà‚ñà‚ñà‚ñà\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9975 best possible recall, 4.33 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.294/0.696-mean/best, past_thr=0.462-mean: 6,25, 16,17, 12,44, 33,31, 10,176, 23,82, 65,56, 29,251, 133,134\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/2     3.39G   0.08624   0.07126   0.05143        22       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2171      23606      0.732      0.169      0.155     0.0674\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/2     3.74G   0.07012   0.06962   0.02846        58       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2171      23606      0.745      0.238      0.248      0.118\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/2     3.74G   0.06476   0.06882   0.02353        25       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2171      23606      0.755      0.255       0.28      0.138\n",
      "Current epoch : 2\n",
      "\n",
      "3 epochs completed in 0.152 hours.\n",
      "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.6MB\n",
      "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.6MB\n",
      "\n",
      "Validating runs/train/exp3/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7082944 parameters, 0 gradients, 16.0 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2171      23606      0.754      0.256       0.28      0.138\n",
      "          wheelchair       2171          7          1          0          0          0\n",
      "               truck       2171        963      0.642      0.493      0.564      0.324\n",
      "          tree_trunk       2171       3172      0.616      0.409      0.469      0.184\n",
      "        traffic_sign       2171       1036      0.596      0.404       0.42      0.223\n",
      "       traffic_light       2171        827      0.573      0.398      0.425      0.163\n",
      "               table       2171         70      0.279     0.0286      0.131     0.0539\n",
      "            stroller       2171         17          1          0    0.00015      3e-05\n",
      "                stop       2171         80          1          0    0.00726      0.003\n",
      "             scooter       2171          9          1          0   0.000211   4.22e-05\n",
      "        potted_plant       2171        614      0.451      0.467      0.445        0.2\n",
      "                pole       2171       2995      0.602      0.454      0.489      0.198\n",
      "              person       2171       2894      0.641      0.597      0.633      0.321\n",
      "       parking_meter       2171          1          1          0          0          0\n",
      "     movable_signage       2171       1012      0.725      0.426      0.508      0.269\n",
      "          motorcycle       2171        391       0.71       0.46      0.572      0.276\n",
      "               kiosk       2171         64          1          0   0.000394   0.000266\n",
      "        fire_hydrant       2171         55          1          0    0.00484    0.00238\n",
      "                 dog       2171          8          1          0   0.000201   0.000121\n",
      "               chair       2171        227      0.494      0.247      0.238      0.105\n",
      "                 cat       2171          3          1          0          0          0\n",
      "             carrier       2171         64          1          0    0.00257   0.000964\n",
      "                 car       2171       6130      0.644      0.838       0.84      0.537\n",
      "                 bus       2171        263      0.762      0.418      0.498      0.289\n",
      "             bollard       2171       1937      0.581      0.539      0.551       0.24\n",
      "             bicycle       2171        397      0.585      0.521      0.524      0.252\n",
      "               bench       2171        274      0.446      0.212      0.223     0.0892\n",
      "           barricade       2171         96          1          0     0.0047    0.00167\n",
      "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First Train YOLOv5s for Aihub parsed dataset\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data parse_1.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [],
   "source": [
    "# Adaptive anchor version, parsed 1~3\n",
    "!python train.py --img 640 --batch 16 --epochs 8 --data parse_1-3.yaml --weights yolov5s.pt --cfg yolov5s_anchor_aihub.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s_anchor_aihub.yaml, data=parse_1-3.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=8, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "fatal: Ïï†Îß§Ìïú Ïù∏Ïûê 'main..origin/master': Ïïå Ïàò ÏóÜÎäî Î¶¨ÎπÑÏ†Ñ ÎòêÎäî ÏûëÏóÖ Ìè¥ÎçîÏóê ÏóÜÎäî Í≤ΩÎ°ú.\n",
      "Í≤ΩÎ°úÏôÄ Î¶¨ÎπÑÏ†ÑÏùÑ Íµ¨Î∂ÑÌïòÎ†§Î©¥ Îã§ÏùåÍ≥º Í∞ôÏù¥ '--'Î•º ÏÇ¨Ïö©ÌïòÏã≠ÏãúÏò§:\n",
      "'git <Î™ÖÎ†π> [<Î¶¨ÎπÑÏ†Ñ>...] -- [<ÌååÏùº>...]'\n",
      "Command 'git rev-list main..origin/master --count' returned non-zero exit status 128.\n",
      "YOLOv5 üöÄ b41502d Python-3.7.2 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=27\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     86304  models.yolo.Detect                      [27, [[6, 25, 16, 17, 12, 44], [33, 31, 10, 176, 23, 81], [65, 56, 29, 251, 133, 134]], [128, 256, 512]]\n",
      "YOLOv5s_anchor_aihub summary: 270 layers, 7092448 parameters, 7092448 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma2/MVP/Aihub/parsed/train/labels' images and labels...\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_000231.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_001512.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_005259.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_007214.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_008382.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_008657.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_010268.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_011766.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_017485.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_018950.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_024380.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_025153.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_028691.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_028695.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_032104.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_039570.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_042876.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_050296.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_052303.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_054046.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_056324.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_059814.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/train/images/MP_SEL_065991.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/soma2/MVP/Aihub/parsed/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma2/MVP/Aihub/parsed/val/labels' images and labels...6405\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: /home/soma2/MVP/Aihub/parsed/val/images/MP_SEL_043595.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/soma2/MVP/Aihub/parsed/val/labels.cache\n",
      "Plotting labels to runs/train/exp7/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.38 anchors/target, 0.998 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp7\u001b[0m\n",
      "Starting training for 8 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0/7     3.39G   0.07692   0.07053   0.04144       109       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.769       0.25      0.269       0.13\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/7     3.75G   0.06396   0.06824   0.02241       135       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.759      0.293      0.326       0.17\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/7     3.75G   0.06103   0.06833   0.01987       103       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.714      0.325      0.354      0.185\n",
      "Current epoch : 2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/7     3.75G   0.05869   0.06784   0.01833       150       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.742      0.345      0.383      0.207\n",
      "Current epoch : 3\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/7     3.75G   0.05711   0.06703   0.01707       130       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.708      0.361      0.407      0.222\n",
      "Current epoch : 4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/7     3.75G   0.05549   0.06646   0.01614       154       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.742      0.381      0.424      0.234\n",
      "Current epoch : 5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/7     3.75G   0.05407   0.06542   0.01526       115       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.739      0.393      0.439      0.247\n",
      "Current epoch : 6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       7/7     3.75G    0.0528   0.06461   0.01455       150       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.741      0.406       0.45      0.254\n",
      "Current epoch : 7\n",
      "\n",
      "8 epochs completed in 1.152 hours.\n",
      "Optimizer stripped from runs/train/exp7/weights/last.pt, 14.6MB\n",
      "Optimizer stripped from runs/train/exp7/weights/best.pt, 14.6MB\n",
      "\n",
      "Validating runs/train/exp7/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s_anchor_aihub summary: 213 layers, 7082944 parameters, 0 gradients, 16.0 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       6405      68170      0.741      0.406       0.45      0.255\n",
      "          wheelchair       6405         13          1          0     0.0257     0.0206\n",
      "               truck       6405       2826      0.717      0.683      0.732      0.487\n",
      "          tree_trunk       6405       9351       0.72      0.619      0.686      0.324\n",
      "        traffic_sign       6405       3003       0.68      0.599      0.627      0.375\n",
      "       traffic_light       6405       2385      0.727      0.641      0.676      0.326\n",
      "               table       6405        217      0.835      0.187      0.354      0.167\n",
      "            stroller       6405         50          1          0     0.0304     0.0133\n",
      "                stop       6405        269      0.667      0.454       0.51      0.286\n",
      "             scooter       6405         31          1          0       0.02     0.0129\n",
      "        potted_plant       6405       1972      0.589      0.545      0.569      0.296\n",
      "                pole       6405       8090      0.719      0.662      0.714      0.369\n",
      "              person       6405       8363      0.721      0.688      0.739      0.412\n",
      "       parking_meter       6405          5          1          0          0          0\n",
      "     movable_signage       6405       2785       0.74      0.582       0.66      0.408\n",
      "          motorcycle       6405       1168      0.764      0.701       0.76      0.424\n",
      "               kiosk       6405        183      0.493      0.164      0.228      0.134\n",
      "        fire_hydrant       6405        158      0.658      0.366      0.456      0.258\n",
      "                 dog       6405         18          1          0    0.00302    0.00211\n",
      "               chair       6405        582       0.56      0.443      0.472      0.237\n",
      "                 cat       6405          5          1          0          0          0\n",
      "             carrier       6405        178      0.439     0.0837      0.137     0.0712\n",
      "                 car       6405      17627      0.775      0.862      0.899      0.641\n",
      "                 bus       6405        836      0.724      0.634      0.684      0.445\n",
      "             bollard       6405       5681      0.741      0.653       0.69      0.381\n",
      "             bicycle       6405       1290      0.639      0.627      0.674      0.371\n",
      "               bench       6405        797      0.622      0.412      0.465      0.237\n",
      "           barricade       6405        287      0.476      0.352      0.338      0.179\n",
      "Results saved to \u001b[1mruns/train/exp7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Adaptive anchor version, parsed 1~3\n",
    "!python train.py --img 640 --batch 16 --epochs 8 --data parse_1-3.yaml --weights yolov5s.pt --cfg yolov5s_anchor_aihub.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=yolov5m_wesee.yaml, data=wesee.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=4, batch_size=16, imgsz=640, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "fatal: ambiguous argument 'main..origin/master': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "Command 'git rev-list main..origin/master --count' returned non-zero exit status 128.\n",
      "YOLOv5 üöÄ 2215c1f Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "YOLOv5m_wesee summary: 369 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 474/481 items from yolov5m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/train/labels' images and l\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/soma4/MVP/dataset/Wesee_parsed/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/val/labels' images and label\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/soma4/MVP/dataset/Wesee_parsed/val/labels.cache\n",
      "Plotting labels to runs/train/exp6/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.76 anchors/target, 0.995 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
      "Starting training for 4 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/3     3.62G   0.05334   0.01152   0.00953        20       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        497     0.0794      0.574     0.0784     0.0398\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/3     4.32G   0.03775  0.007514   0.00253        20       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        497      0.119      0.507      0.092     0.0565\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/3     4.32G   0.03364    0.0071  0.002111        20       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        497     0.0869      0.707      0.104     0.0576\n",
      "Current epoch : 2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/3     4.32G   0.02785  0.006497  0.001435        20       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        497     0.0924      0.747      0.104     0.0686\n",
      "Current epoch : 3\n",
      "\n",
      "4 epochs completed in 0.436 hours.\n",
      "Optimizer stripped from runs/train/exp6/weights/last.pt, 42.2MB\n",
      "Optimizer stripped from runs/train/exp6/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating runs/train/exp6/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        497     0.0924      0.747      0.104     0.0686\n",
      "         Zebra_Cross       3734        362     0.0923      0.862      0.101     0.0864\n",
      "            R_Signal       3734        102     0.0813      0.863      0.102     0.0539\n",
      "            G_Signal       3734         33      0.104      0.515       0.11     0.0655\n",
      "Results saved to \u001b[1mruns/train/exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First Wesee training, 640*360 imgsize\n",
    "!python train.py --img 640 --rect --batch 16 --epochs 4 --data wesee.yaml --weights yolov5m.pt --cfg yolov5m_wesee.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=first_wesee_m.pt, cfg=yolov5m_wesee.yaml, data=wesee.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=2, batch_size=16, imgsz=640, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "fatal: ambiguous argument 'main..origin/master': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "Command 'git rev-list main..origin/master --count' returned non-zero exit status 128.\n",
      "YOLOv5 üöÄ 2215c1f Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "YOLOv5m_wesee summary: 369 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 480/481 items from first_wesee_m.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/train/labels.cache' images\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/val/labels.cache' images and\u001b[0m\n",
      "Plotting labels to runs/train/exp9/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.77 anchors/target, 0.995 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp9\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/1     3.62G   0.02374  0.005901 0.0009725        18       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        518      0.102      0.757      0.105     0.0695\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/1     4.32G   0.02375   0.00572 0.0009998        18       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        518     0.0984      0.765      0.105     0.0673\n",
      "Current epoch : 1\n",
      "\n",
      "2 epochs completed in 0.219 hours.\n",
      "Optimizer stripped from runs/train/exp9/weights/last.pt, 42.2MB\n",
      "Optimizer stripped from runs/train/exp9/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating runs/train/exp9/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3734        518      0.103      0.757      0.105     0.0694\n",
      "         Zebra_Cross       3734        365     0.0946      0.899      0.101     0.0823\n",
      "            R_Signal       3734        114        0.1      0.807      0.109     0.0675\n",
      "            G_Signal       3734         39      0.113      0.564      0.105     0.0583\n",
      "Results saved to \u001b[1mruns/train/exp9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# M-model Wesee training, 640*360 imgsize, pretrained\n",
    "!python train.py --img 640 --rect --batch 16 --epochs 2 --data wesee.yaml --weights first_wesee_m.pt --cfg yolov5m_wesee.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=wesee_80.pt, cfg=yolov5m_wesee.yaml, data=wesee.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=16, imgsz=640, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "fatal: ambiguous argument 'jpeg..origin/master': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "Command 'git rev-list jpeg..origin/master --count' returned non-zero exit status 128.\n",
      "YOLOv5 üöÄ a79d83e Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "YOLOv5m_wesee summary: 369 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 480/481 items from wesee_80.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/train/labels' images and l\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/soma4/MVP/dataset/Wesee_parsed/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/val/labels.cache' images and\u001b[0m\n",
      "Plotting labels to runs/train/exp13/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.75 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp13\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/59     3.63G   0.01707  0.004304 0.0006495         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.905      0.929      0.952      0.751\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/59     4.33G    0.0185  0.004417 0.0007871         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.888       0.94      0.948      0.732\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/59     4.33G   0.02078   0.00498 0.0009356         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.886      0.903      0.932      0.676\n",
      "Current epoch : 2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/59     4.33G   0.02421  0.006048  0.001218         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.867      0.842      0.893       0.63\n",
      "Current epoch : 3\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/59     4.33G   0.02391   0.00581    0.0012         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.882      0.883      0.916      0.675\n",
      "Current epoch : 4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/59     4.33G   0.02322  0.005817  0.001162         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.889      0.904      0.928       0.67\n",
      "Current epoch : 5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/59     4.33G   0.02261  0.005529  0.001016         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.889      0.878       0.92      0.678\n",
      "Current epoch : 6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/59     4.33G   0.02237    0.0054  0.001074         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030       0.87      0.921      0.929      0.694\n",
      "Current epoch : 7\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/59     4.33G   0.02183  0.005267 0.0009718         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.885      0.922      0.932      0.704\n",
      "Current epoch : 8\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/59     4.33G   0.02156  0.005228 0.0009888         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.868      0.929      0.932      0.705\n",
      "Current epoch : 9\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/59     4.33G   0.02111  0.005168 0.0009821         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.897      0.905      0.937      0.716\n",
      "Current epoch : 10\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/59     4.33G   0.02109  0.005121  0.000869         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.885      0.921      0.935      0.715\n",
      "Current epoch : 11\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/59     4.33G   0.02102  0.005097 0.0009901         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.872      0.933       0.93      0.714\n",
      "Current epoch : 12\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/59     4.33G   0.02092  0.005069 0.0009967         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.896       0.91      0.939      0.723\n",
      "Current epoch : 13\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/59     4.33G   0.02037  0.004973 0.0008569         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030       0.89      0.928      0.942      0.731\n",
      "Current epoch : 14\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/59     4.33G   0.02041   0.00495 0.0009408         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.888      0.929      0.946      0.736\n",
      "Current epoch : 15\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/59     4.33G   0.02029  0.004909 0.0009149         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.888      0.921      0.942      0.735\n",
      "Current epoch : 16\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/59     4.33G   0.01993  0.004898 0.0009565         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.896      0.921      0.945       0.74\n",
      "Current epoch : 17\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/59     4.33G    0.0199  0.004864 0.0008863         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.884      0.933      0.946      0.743\n",
      "Current epoch : 18\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/59     4.33G   0.02037  0.004929 0.0009731         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.891      0.932      0.941      0.736\n",
      "Current epoch : 19\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/59     4.33G   0.02001  0.004911 0.0009377         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.887      0.928       0.94      0.737\n",
      "Current epoch : 20\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/59     4.33G   0.01967  0.004787 0.0009923         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.889      0.933       0.94      0.741\n",
      "Current epoch : 21\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/59     4.33G   0.01938  0.004732 0.0008881         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.891       0.94      0.944      0.745\n",
      "Current epoch : 22\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/59     4.33G   0.01943  0.004714 0.0008626         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.886      0.939      0.947      0.747\n",
      "Current epoch : 23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/59     4.33G   0.01913  0.004742 0.0008596         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.888      0.941      0.947      0.749\n",
      "Current epoch : 24\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/59     4.33G   0.01897  0.004672 0.0008637         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.886      0.941      0.946      0.749\n",
      "Current epoch : 25\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/59     4.33G    0.0187  0.004598 0.0008223         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030       0.89      0.943      0.948      0.752\n",
      "Current epoch : 26\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/59     4.33G   0.01858   0.00459 0.0008276         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.898      0.933      0.949      0.752\n",
      "Current epoch : 27\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/59     4.33G   0.01857  0.004614 0.0008277         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.896      0.937      0.948      0.753\n",
      "Current epoch : 28\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/59     4.33G   0.01844  0.004541 0.0007803         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.897      0.939       0.95      0.754\n",
      "Current epoch : 29\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     30/59     4.33G   0.01833   0.00452 0.0007601         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895      0.942       0.95      0.756\n",
      "Current epoch : 30\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     31/59     4.33G   0.01813  0.004505 0.0007995         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.894      0.941      0.951      0.757\n",
      "Current epoch : 31\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     32/59     4.33G   0.01807   0.00448 0.0008407         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.894       0.94      0.951      0.758\n",
      "Current epoch : 32\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     33/59     4.33G   0.01801  0.004442 0.0007336         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.897      0.938      0.952      0.759\n",
      "Current epoch : 33\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     34/59     4.33G   0.01777  0.004394 0.0007758         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.894      0.941      0.952       0.76\n",
      "Current epoch : 34\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     35/59     4.33G   0.01743  0.004359 0.0007511         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895      0.939      0.952       0.76\n",
      "Current epoch : 35\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     36/59     4.33G   0.01734  0.004308 0.0006977         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895       0.94      0.952       0.76\n",
      "Current epoch : 36\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     37/59     4.33G   0.01712   0.00427 0.0007179         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895      0.941      0.953      0.761\n",
      "Current epoch : 37\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     38/59     4.33G   0.01701  0.004258 0.0006952         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.896       0.94      0.953      0.761\n",
      "Current epoch : 38\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     39/59     4.33G   0.01675  0.004191 0.0006936         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.941      0.953      0.762\n",
      "Current epoch : 39\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     40/59     4.33G   0.01681  0.004181 0.0007121         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.941      0.954      0.762\n",
      "Current epoch : 40\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     41/59     4.33G   0.01663  0.004138 0.0007135         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.942      0.953      0.763\n",
      "Current epoch : 41\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     42/59     4.33G   0.01642  0.004079 0.0006703         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.942      0.953      0.763\n",
      "Current epoch : 42\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     43/59     4.33G   0.01639  0.004081 0.0006843         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.943      0.953      0.764\n",
      "Current epoch : 43\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     44/59     4.33G   0.01613  0.004077 0.0006441         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.943      0.953      0.764\n",
      "Current epoch : 44\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     45/59     4.33G   0.01589  0.004008 0.0006113         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.945      0.953      0.765\n",
      "Current epoch : 45\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     46/59     4.33G   0.01573  0.003971 0.0006609         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.894      0.945      0.953      0.765\n",
      "Current epoch : 46\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     47/59     4.33G   0.01578  0.003963 0.0006252         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.894      0.946      0.954      0.766\n",
      "Current epoch : 47\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     48/59     4.33G   0.01545  0.003914 0.0006219         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895      0.946      0.954      0.766\n",
      "Current epoch : 48\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     49/59     4.33G    0.0152  0.003859 0.0005521         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895      0.945      0.954      0.767\n",
      "Current epoch : 49\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     50/59     4.33G   0.01508  0.003841 0.0005675         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.896      0.946      0.954      0.767\n",
      "Current epoch : 50\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     51/59     4.33G    0.0149   0.00377 0.0005567         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.894      0.948      0.955      0.768\n",
      "Current epoch : 51\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     52/59     4.33G   0.01481  0.003757 0.0005907         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.895      0.949      0.955      0.768\n",
      "Current epoch : 52\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     53/59     4.33G   0.01451    0.0037 0.0005661         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.896      0.948      0.956      0.768\n",
      "Current epoch : 53\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     54/59     4.33G   0.01434  0.003658  0.000499         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.897      0.948      0.956      0.769\n",
      "Current epoch : 54\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     55/59     4.33G   0.01423  0.003616 0.0005135         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.897      0.946      0.956      0.769\n",
      "Current epoch : 55\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     56/59     4.33G   0.01411  0.003598 0.0005427         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.898      0.946      0.956       0.77\n",
      "Current epoch : 56\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     57/59     4.33G   0.01386  0.003559 0.0005425         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.899      0.945      0.956       0.77\n",
      "Current epoch : 57\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     58/59     4.33G   0.01368   0.00354 0.0005143         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030        0.9      0.946      0.956       0.77\n",
      "Current epoch : 58\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     59/59     4.33G    0.0135  0.003498 0.0005098         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.901      0.945      0.956      0.771\n",
      "Current epoch : 59\n",
      "\n",
      "60 epochs completed in 6.508 hours.\n",
      "Optimizer stripped from runs/train/exp13/weights/last.pt, 42.2MB\n",
      "Optimizer stripped from runs/train/exp13/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating runs/train/exp13/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.902       0.94      0.956       0.77\n",
      "         Zebra_Cross       3594       3619      0.976      0.955      0.982      0.927\n",
      "            R_Signal       3594       1021       0.85      0.949      0.944      0.703\n",
      "            G_Signal       3594        390       0.88      0.915      0.943      0.681\n",
      "Results saved to \u001b[1mruns/train/exp13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Extra epochs! M-model Wesee training, 640*360 imgsize, pretrained\n",
    "!python train.py --img 640 --rect --batch 16 --epochs 60 --data wesee.yaml --weights wesee_80.pt --cfg yolov5m_wesee.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [],
   "source": [
    "# Extra epochs! L-model Wesee training, 640*360 imgsize, pretrained\n",
    "!python train.py --img 640 --rect --batch 16 --epochs 5 --data wesee.yaml --weights yolov5l.pt # --cfg yolov5l_wesee.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=wesee_80.pt, cfg=yolov5m_wesee.yaml, data=wesee_compress.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=80, batch_size=16, imgsz=640, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=compress-50, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "fatal: ambiguous argument 'jpeg..origin/master': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n",
      "Command 'git rev-list jpeg..origin/master --count' returned non-zero exit status 128.\n",
      "YOLOv5 üöÄ a79d83e Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     32328  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "YOLOv5m_wesee summary: 369 layers, 20879400 parameters, 20879400 gradients, 48.2 GFLOPs\n",
      "\n",
      "Transferred 480/481 items from wesee_80.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n",
      "WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_jpg50/train/labels.cache' images \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_jpg50/val/labels.cache' images and \u001b[0m\n",
      "Plotting labels to runs/train/compress-50/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.75 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/compress-50\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/79     3.62G   0.01768  0.004417 0.0006346        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.898      0.928      0.942      0.736\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/79     4.32G   0.01939  0.004563 0.0006853        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.898      0.911      0.934      0.704\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/79     4.32G   0.02174  0.005129  0.001022        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052       0.88      0.888      0.906      0.648\n",
      "Current epoch : 2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/79     4.32G   0.02459  0.005879  0.001286        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052       0.88      0.863        0.9      0.653\n",
      "Current epoch : 3\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/79     4.32G   0.02407  0.005722  0.001152        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.878      0.881      0.914      0.667\n",
      "Current epoch : 4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/79     4.32G   0.02351  0.005619  0.001214        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.875      0.894      0.913      0.657\n",
      "Current epoch : 5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/79     4.32G   0.02339  0.005579   0.00114        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.899      0.915      0.677\n",
      "Current epoch : 6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/79     4.32G   0.02264  0.005438  0.001079        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.881      0.903       0.92      0.673\n",
      "Current epoch : 7\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/79     4.32G   0.02261  0.005356  0.001006        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.902      0.891      0.924      0.689\n",
      "Current epoch : 8\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/79     4.32G   0.02237  0.005374  0.001112        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.916       0.93      0.704\n",
      "Current epoch : 9\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/79     4.32G   0.02199  0.005253 0.0009559        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.883      0.909      0.928      0.695\n",
      "Current epoch : 10\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/79     4.32G   0.02168  0.005188 0.0009257        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052       0.89      0.908      0.923      0.705\n",
      "Current epoch : 11\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/79     4.32G   0.02162  0.005179 0.0009882        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.889      0.904      0.926      0.709\n",
      "Current epoch : 12\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/79     4.32G   0.02144  0.005139 0.0009483        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.882      0.924      0.932       0.71\n",
      "Current epoch : 13\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/79     4.32G   0.02109    0.0051  0.001054        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.901      0.914      0.934       0.72\n",
      "Current epoch : 14\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/79     4.32G   0.02139  0.005072 0.0008691        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895       0.92      0.938      0.726\n",
      "Current epoch : 15\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/79     4.32G   0.02127  0.005083  0.001023        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.901      0.907      0.934      0.721\n",
      "Current epoch : 16\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/79     4.32G   0.02128  0.005023 0.0009672        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.918      0.937      0.728\n",
      "Current epoch : 17\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/79     4.32G     0.021  0.005005  0.001025        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.925      0.937      0.732\n",
      "Current epoch : 18\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/79     4.32G   0.02109  0.005096 0.0009802        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.893      0.925      0.936      0.732\n",
      "Current epoch : 19\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/79     4.32G   0.02093  0.005053 0.0009502        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897      0.918      0.938      0.735\n",
      "Current epoch : 20\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/79     4.32G   0.02079  0.004955 0.0008999        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.898      0.911       0.94      0.737\n",
      "Current epoch : 21\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/79     4.32G   0.02035  0.004916  0.000834        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.887      0.933      0.943       0.74\n",
      "Current epoch : 22\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/79     4.32G   0.02048  0.004893 0.0009653        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.922      0.939      0.739\n",
      "Current epoch : 23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/79     4.32G   0.02038  0.004897 0.0008928        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.901      0.918       0.94      0.739\n",
      "Current epoch : 24\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/79     4.32G   0.02014  0.004827  0.000888        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.924       0.94       0.74\n",
      "Current epoch : 25\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/79     4.32G    0.0201  0.004795  0.000922        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052       0.89      0.935       0.94      0.742\n",
      "Current epoch : 26\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/79     4.32G   0.01989  0.004782 0.0008717        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.889      0.937      0.941      0.742\n",
      "Current epoch : 27\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/79     4.32G   0.01989  0.004802  0.000882        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.888      0.941      0.941      0.744\n",
      "Current epoch : 28\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/79     4.32G   0.01978  0.004793 0.0008413        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.886      0.939      0.941      0.745\n",
      "Current epoch : 29\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     30/79     4.32G   0.01981  0.004736  0.000828        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.885       0.94      0.941      0.746\n",
      "Current epoch : 30\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     31/79     4.32G   0.01949  0.004752  0.000858        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.887      0.938      0.941      0.748\n",
      "Current epoch : 31\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32/79     4.32G   0.01939  0.004696 0.0008661        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.883      0.942      0.941      0.748\n",
      "Current epoch : 32\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     33/79     4.32G   0.01925  0.004641 0.0008091        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.886      0.938      0.941      0.749\n",
      "Current epoch : 33\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     34/79     4.32G    0.0191  0.004595 0.0008137        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.888      0.934      0.941       0.75\n",
      "Current epoch : 34\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     35/79     4.32G   0.01894  0.004629 0.0007691        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.892      0.934      0.941      0.751\n",
      "Current epoch : 35\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     36/79     4.32G   0.01916  0.004628 0.0008682        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897      0.933      0.941      0.752\n",
      "Current epoch : 36\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     37/79     4.32G   0.01879  0.004577 0.0007386        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.934      0.942      0.753\n",
      "Current epoch : 37\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     38/79     4.32G    0.0186  0.004528 0.0007655        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.934      0.942      0.753\n",
      "Current epoch : 38\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     39/79     4.32G   0.01868  0.004553 0.0009683        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.935      0.942      0.754\n",
      "Current epoch : 39\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     40/79     4.32G    0.0187  0.004557 0.0007352        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.934      0.943      0.754\n",
      "Current epoch : 40\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     41/79     4.32G    0.0183  0.004487 0.0007516        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.936      0.943      0.754\n",
      "Current epoch : 41\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     42/79     4.32G   0.01831  0.004456 0.0007608        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.891      0.935      0.943      0.755\n",
      "Current epoch : 42\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     43/79     4.32G   0.01825  0.004422 0.0007281        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.934      0.943      0.756\n",
      "Current epoch : 43\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     44/79     4.32G   0.01811  0.004435 0.0007967        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.932      0.943      0.755\n",
      "Current epoch : 44\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     45/79     4.32G   0.01808  0.004441 0.0007095        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.933      0.943      0.756\n",
      "Current epoch : 45\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     46/79     4.32G   0.01793  0.004383 0.0007081        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.933      0.944      0.757\n",
      "Current epoch : 46\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     47/79     4.32G   0.01759   0.00433 0.0006845        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.894      0.933      0.944      0.756\n",
      "Current epoch : 47\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     48/79     4.32G   0.01762  0.004307 0.0006458        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.932      0.944      0.757\n",
      "Current epoch : 48\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     49/79     4.32G   0.01759    0.0043 0.0006069        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.932      0.944      0.756\n",
      "Current epoch : 49\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     50/79     4.32G   0.01747  0.004295 0.0007003        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.932      0.944      0.757\n",
      "Current epoch : 50\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     51/79     4.32G   0.01744  0.004289 0.0006732        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.931      0.944      0.758\n",
      "Current epoch : 51\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     52/79     4.32G   0.01709   0.00427 0.0006751        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.932      0.945      0.758\n",
      "Current epoch : 52\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     53/79     4.32G   0.01697   0.00425 0.0006637        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.932      0.945      0.759\n",
      "Current epoch : 53\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     54/79     4.32G   0.01683  0.004189 0.0006309        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.932      0.945      0.759\n",
      "Current epoch : 54\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     55/79     4.32G   0.01665  0.004141 0.0005908        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.932      0.946       0.76\n",
      "Current epoch : 55\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     56/79     4.32G   0.01658  0.004132 0.0006981        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.895      0.932      0.946       0.76\n",
      "Current epoch : 56\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     57/79     4.32G   0.01646  0.004106 0.0005942        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.932      0.946      0.761\n",
      "Current epoch : 57\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     58/79     4.32G   0.01642  0.004058  0.000557        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.931      0.946      0.761\n",
      "Current epoch : 58\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     59/79     4.32G   0.01622  0.004035 0.0006111        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897       0.93      0.946      0.761\n",
      "Current epoch : 59\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     60/79     4.32G   0.01629  0.004057 0.0006398        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897       0.93      0.946      0.761\n",
      "Current epoch : 60\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     61/79     4.32G   0.01598  0.003965 0.0006303        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897      0.929      0.947      0.762\n",
      "Current epoch : 61\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     62/79     4.32G   0.01574  0.003967  0.000605        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897      0.932      0.947      0.763\n",
      "Current epoch : 62\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     63/79     4.32G   0.01557  0.003907 0.0005371        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052        0.9      0.931      0.947      0.762\n",
      "Current epoch : 63\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     64/79     4.32G   0.01558  0.003912  0.000528        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.899      0.934      0.947      0.763\n",
      "Current epoch : 64\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     65/79     4.32G    0.0155  0.003898 0.0005185        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.902      0.931      0.947      0.763\n",
      "Current epoch : 65\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     66/79     4.32G   0.01529  0.003854 0.0005496        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.902      0.929      0.948      0.763\n",
      "Current epoch : 66\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     67/79     4.32G   0.01511  0.003773 0.0005939        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.904      0.927      0.948      0.763\n",
      "Current epoch : 67\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     68/79     4.32G   0.01499   0.00379 0.0004782        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.903      0.931      0.948      0.764\n",
      "Current epoch : 68\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     69/79     4.32G   0.01493  0.003766 0.0005571        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.904       0.93      0.948      0.765\n",
      "Current epoch : 69\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     70/79     4.32G   0.01467  0.003727 0.0004722        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.941      0.948      0.764\n",
      "Current epoch : 70\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     71/79     4.32G   0.01458  0.003665 0.0004919        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.896      0.941      0.948      0.764\n",
      "Current epoch : 71\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     72/79     4.32G   0.01439  0.003632 0.0005108        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.897       0.94      0.948      0.764\n",
      "Current epoch : 72\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     73/79     4.32G   0.01423  0.003625  0.000475        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.898       0.94      0.948      0.764\n",
      "Current epoch : 73\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     74/79     4.32G   0.01408  0.003566 0.0004324        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.898       0.94      0.948      0.765\n",
      "Current epoch : 74\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     75/79     4.32G   0.01394  0.003525 0.0004251        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.899       0.94      0.949      0.765\n",
      "Current epoch : 75\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     76/79     4.32G   0.01384  0.003514 0.0004086        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052        0.9       0.94      0.949      0.765\n",
      "Current epoch : 76\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     77/79     4.32G   0.01358   0.00346 0.0004037        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052        0.9       0.94      0.949      0.765\n",
      "Current epoch : 77\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     78/79     4.32G   0.01346  0.003436 0.0004428        27       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.901       0.94      0.949      0.765\n",
      "Current epoch : 78\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     79/79     4.32G   0.01333  0.003399 0.0003915        26       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.901       0.94      0.949      0.765\n",
      "Current epoch : 79\n",
      "\n",
      "80 epochs completed in 8.647 hours.\n",
      "Optimizer stripped from runs/train/compress-50/weights/last.pt, 42.2MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs/train/compress-50/weights/best.pt, 42.2MB\n",
      "\n",
      "Validating runs/train/compress-50/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.899       0.94      0.949      0.766\n",
      "         Zebra_Cross       3618       3639      0.974      0.957      0.983      0.927\n",
      "            R_Signal       3618       1027       0.87      0.951      0.946      0.697\n",
      "            G_Signal       3618        386      0.853      0.912      0.917      0.672\n",
      "Results saved to \u001b[1mruns/train/compress-50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compressed image M-model Wesee training, 640*360 imgsize, no tranied\n",
    "!python train.py --img 640 --rect --batch 16 --epochs 80 --data wesee_compress.yaml --weights wesee_80.pt --cfg yolov5m_wesee.yaml --name compress-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 2. Validate\n",
    "Validate a model's accuracy on [COCO](https://cocodataset.org/#home) val or test-dev datasets. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Validation\n",
    "!python3 val.py --weight mask.pt --img 640 --iou 0.65 --half --data /home/soma2/MVP/roboflow_mask_dataset/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "1434668c-e1de-43a4-fded-e91323452103"
   },
   "outputs": [],
   "source": [
    "# Run YOLOv5x on COCO val\n",
    "!python val.py --weights yolov5x.pt --data coco.yaml --img 640 --iou 0.65 --half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "1434668c-e1de-43a4-fded-e91323452103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/soma4/MVP/voyager-Vision-task/data/wesee.yaml, weights=['wesee_80.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=original, exist_ok=False, half=True, dnn=False\n",
      "YOLOv5 üöÄ a79d83e Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_parsed/val/labels.cache' images and\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030       0.89      0.945      0.946      0.758\n",
      "         Zebra_Cross       3594       3619      0.978      0.949      0.982      0.923\n",
      "            R_Signal       3594       1021      0.827      0.957       0.93       0.69\n",
      "            G_Signal       3594        390      0.863      0.928      0.924      0.659\n",
      "Speed: 0.1ms pre-process, 1.6ms inference, 0.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/original\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Wesee original val\n",
    "!python val.py --weights wesee_80.pt --data wesee.yaml --img 640 --iou 0.65 --half --name original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "1434668c-e1de-43a4-fded-e91323452103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/soma4/MVP/voyager-Vision-task/data/wesee_compress.yaml, weights=['wesee_80.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=compress-50, exist_ok=False, half=True, dnn=False\n",
      "YOLOv5 üöÄ a79d83e Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma4/MVP/dataset/Wesee_jpg50/val/labels.cache' images and \u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3618       5052      0.888      0.934      0.941      0.748\n",
      "         Zebra_Cross       3618       3639      0.979      0.954      0.982      0.923\n",
      "            R_Signal       3618       1027      0.847      0.953      0.933      0.674\n",
      "            G_Signal       3618        386      0.838      0.896      0.909      0.647\n",
      "Speed: 0.1ms pre-process, 1.6ms inference, 0.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/compress-50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Wesee compressed 50 val\n",
    "!python val.py --weights wesee_80.pt --data wesee_compress.yaml --img 640 --iou 0.65 --half --name compress-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 3. Inference\n",
    "\n",
    "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
    "\n",
    "```shell\n",
    "python detect.py --source 0  # webcam\n",
    "                          img.jpg  # image \n",
    "                          vid.mp4  # video\n",
    "                          path/  # directory\n",
    "                          path/*.jpg  # glob\n",
    "                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "zR9ZbuQCH7FX",
    "outputId": "a4dd083d-211f-4e81-aa1c-a263b330a719"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ../data/images\n",
    "display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['wesee_80.pt'], source=data/my_images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 üöÄ 2d10121 Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/6 /home/soma4/MVP/voyager-Vision-task/data/my_images/MP_KSC_001134.jpg: 384x640 1 Zebra_Cross, 1 R_Signal, Done. (0.012s)\n",
      "image 2/6 /home/soma4/MVP/voyager-Vision-task/data/my_images/MP_KSC_001581.jpg: 384x640 1 Zebra_Cross, 1 R_Signal, Done. (0.009s)\n",
      "image 3/6 /home/soma4/MVP/voyager-Vision-task/data/my_images/MP_KSC_002217.jpg: 384x640 1 G_Signal, Done. (0.009s)\n",
      "image 4/6 /home/soma4/MVP/voyager-Vision-task/data/my_images/MP_KSC_006199.jpg: 384x640 1 Zebra_Cross, 1 G_Signal, Done. (0.009s)\n",
      "image 5/6 /home/soma4/MVP/voyager-Vision-task/data/my_images/MP_KSC_006353.jpg: 384x640 1 R_Signal, Done. (0.009s)\n",
      "image 6/6 /home/soma4/MVP/voyager-Vision-task/data/my_images/MP_KSC_008678.jpg: 384x640 1 Zebra_Cross, 1 R_Signal, Done. (0.009s)\n",
      "Speed: 0.3ms pre-process, 9.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# My Inference\n",
    "!python detect.py --weights wesee_80.pt --img 640 --conf 0.25 --source data/my_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['wesee_80.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 üöÄ a79d83e Python-3.8.10 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24267MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m_wesee summary: 290 layers, 20861016 parameters, 0 gradients, 47.9 GFLOPs\n",
      "image 1/2 /home/soma4/MVP/voyager-Vision-task/data/images/MP_SEL_B013378.jpg: 384x640 1 Zebra_Cross, 1 R_Signal, Done. (0.012s)\n",
      "image 2/2 /home/soma4/MVP/voyager-Vision-task/data/images/what.jpg: 384x640 1 G_Signal, Done. (0.010s)\n",
      "Speed: 0.3ms pre-process, 10.7ms inference, 0.8ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# My Inference\n",
    "!python detect.py --weights wesee_80.pt --img 640 --conf 0.25 --source data/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15glLzbQx5u0"
   },
   "source": [
    "# 4. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "## Weights & Biases Logging üåü NEW\n",
    "\n",
    "[Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_notebook) (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. To enable W&B `pip install wandb`, and then train normally (you will be guided through setup on first use). \n",
    "\n",
    "During training you will see live updates at [https://wandb.ai/home](https://wandb.ai/home?utm_campaign=repo_yolo_notebook), and you can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. For more information see the [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
    "\n",
    "<p align=\"left\"><img width=\"900\" alt=\"Weights & Biases dashboard\" src=\"https://user-images.githubusercontent.com/26833433/135390767-c28b050f-8455-4004-adb0-3b730386e2b2.png\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [],
   "source": [
    "# Tensorboard  (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fLAV42oNb7M"
   },
   "outputs": [],
   "source": [
    "# Weights & Biases  (optional)\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Appendix\n",
    "\n",
    "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcKoSIK2WSzj"
   },
   "outputs": [],
   "source": [
    "# Reproduce\n",
    "for x in 'yolov5n', 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x':\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --task speed  # speed\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMusP4OAxFu6"
   },
   "outputs": [],
   "source": [
    "# PyTorch Hub\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Images\n",
    "dir = 'https://ultralytics.com/images/'\n",
    "imgs = [dir + f for f in ('zidane.jpg', 'bus.jpg')]  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "results.print()  # or .show(), .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGH0ZjkGjejy"
   },
   "outputs": [],
   "source": [
    "# CI Checks\n",
    "%%shell\n",
    "export PYTHONPATH=\"$PWD\"  # to run *.py. files in subdirectories\n",
    "rm -rf runs  # remove runs/\n",
    "for m in yolov5n; do  # models\n",
    "  python train.py --img 64 --batch 32 --weights $m.pt --epochs 1 --device 0  # train pretrained\n",
    "  python train.py --img 64 --batch 32 --weights '' --cfg $m.yaml --epochs 1 --device 0  # train scratch\n",
    "  for d in 0 cpu; do  # devices\n",
    "    python val.py --weights $m.pt --device $d # val official\n",
    "    python val.py --weights runs/train/exp/weights/best.pt --device $d # val custom\n",
    "    python detect.py --weights $m.pt --device $d  # detect official\n",
    "    python detect.py --weights runs/train/exp/weights/best.pt --device $d  # detect custom\n",
    "  done\n",
    "  python hubconf.py  # hub\n",
    "  python models/yolo.py --cfg $m.yaml  # build PyTorch model\n",
    "  python models/tf.py --weights $m.pt  # build TensorFlow model\n",
    "  python export.py --img 64 --batch 1 --weights $m.pt --include torchscript onnx  # export\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gogI-kwi3Tye"
   },
   "outputs": [],
   "source": [
    "# Profile\n",
    "from utils.torch_utils import profile\n",
    "\n",
    "m1 = lambda x: x * torch.sigmoid(x)\n",
    "m2 = torch.nn.SiLU()\n",
    "results = profile(input=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVRSOhEvUdb5"
   },
   "outputs": [],
   "source": [
    "# Evolve\n",
    "!python train.py --img 640 --batch 64 --epochs 100 --data coco128.yaml --weights yolov5s.pt --cache --noautoanchor --evolve\n",
    "!d=runs/train/evolve && cp evolve.* $d && zip -r evolve.zip $d && gsutil mv evolve.zip gs://bucket  # upload results (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSgFCAcMbk1R"
   },
   "outputs": [],
   "source": [
    "# VOC\n",
    "for b, m in zip([64, 64, 64, 32, 16], ['yolov5n', 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x']):  # batch, model\n",
    "  !python train.py --batch {b} --weights {m}.pt --data VOC.yaml --epochs 50 --img 512 --hyp hyp.VOC.yaml --project VOC --name {m} --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTRwsvA9u7ln"
   },
   "outputs": [],
   "source": [
    "# TensorRT \n",
    "# https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-pip\n",
    "!pip install -U nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com  # install\n",
    "!python export.py --weights yolov5s.pt --include engine --imgsz 640 --device 0  # export\n",
    "!python detect.py --weights yolov5s.engine --imgsz 640 --device 0  # inference"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "YOLOv5 basic",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "037b09477fa14aa097d2b64af501ba03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13bc45f3b9c444a99c57325a6f59230e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bc42fbf6b6f44d6acb68612c70faa5f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a280c3595d7241fda184d93295b44a56",
      "value": " 780M/780M [00:07&lt;00:00, 130MB/s]"
     }
    },
    "1bc42fbf6b6f44d6acb68612c70faa5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "202a9fce8f2543efaaa2ed8c9d42d920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "207c4f4e92a04e79901d9acf83c9b446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_441f56ccb78e4a60b84212329e7adc51",
       "IPY_MODEL_94412b579e7048839e8af8f34c76b9e4",
       "IPY_MODEL_13bc45f3b9c444a99c57325a6f59230e"
      ],
      "layout": "IPY_MODEL_037b09477fa14aa097d2b64af501ba03"
     }
    },
    "35ea2fd621b147edbd26ca4954be998f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ba18e6a4d2f4949ab2bdf6b4f7ad59e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "441f56ccb78e4a60b84212329e7adc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba18e6a4d2f4949ab2bdf6b4f7ad59e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f6e7b35f07e14dd3a41065669dd57b0c",
      "value": "100%"
     }
    },
    "578f046b1bc54c48b604fee25aca1035": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57b2d73efed0488b9d1748cd2d1e9b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6707a12a2ad947a2a7a347950623302d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72c229969ac84481a058279dafa1fdc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82f5601bd90b4ada9cec87011904e734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b4a53b9e0fd40018a5fc0672c16351e",
       "IPY_MODEL_f10ccba7201447608a079c5757cb6828",
       "IPY_MODEL_fefc249a1de64fd28eb7b32a9ce313a6"
      ],
      "layout": "IPY_MODEL_a4e252dbc8fb4b5aa681970c64210146"
     }
    },
    "94412b579e7048839e8af8f34c76b9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35ea2fd621b147edbd26ca4954be998f",
      "max": 818322941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57b2d73efed0488b9d1748cd2d1e9b9d",
      "value": 818322941
     }
    },
    "9b4a53b9e0fd40018a5fc0672c16351e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b04963a9b74e4451a525f81c4768c295",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_202a9fce8f2543efaaa2ed8c9d42d920",
      "value": "100%"
     }
    },
    "a280c3595d7241fda184d93295b44a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4e252dbc8fb4b5aa681970c64210146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b04963a9b74e4451a525f81c4768c295": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ce35d2764a43cf949765a3d499eba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f10ccba7201447608a079c5757cb6828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72c229969ac84481a058279dafa1fdc1",
      "max": 71005511,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6707a12a2ad947a2a7a347950623302d",
      "value": 71005511
     }
    },
    "f6e7b35f07e14dd3a41065669dd57b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fefc249a1de64fd28eb7b32a9ce313a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_578f046b1bc54c48b604fee25aca1035",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e5ce35d2764a43cf949765a3d499eba8",
      "value": " 67.7M/67.7M [00:00&lt;00:00, 110MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
