{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Jupyter-notebook for Local machine, GTX3090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/soma2/MVP\n",
    "# !git clone https://github.com/biancco/SOMA-vision-task.git  # clone\n",
    "\n",
    "%cd voyager-Vision-task\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "%pip install -qr requirements_local.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "5e22f100-fe2e-4390-dfee-cc019821be25"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 1. Train\n",
    "Train \\*.pt through \"train.py\" python script with options<br>\n",
    "```shell\n",
    "    --cfg  model.yaml\n",
    "    --weight  yolov5s.pt\n",
    "    --img  640\n",
    "    --batch  16\n",
    "    --epochs  10\n",
    "    --data  data.yaml\n",
    "    --save-period  1\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "223f7018-b5ab-45cd-a918-47a3020be853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=wesee_l_v1.pt, cfg=, data=chair.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=640, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=chair_l_0805, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 üöÄ 2022-8-4 Python-3.7.2 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=3 with nc=22\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1    145395  models.yolo.Detect                      [22, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model summary: 468 layers, 46251379 parameters, 46251379 gradients, 108.6 GFLOPs\n",
      "\n",
      "Transferred 607/613 items from wesee_l_v1.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 101 weight (no decay), 104 weight, 104 bias\n",
      "WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma2/MVP/dataset/Chair_parsed/train/labels.cache' images\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/dataset/Chair_parsed/train/images/ÌÉÑÏ≤ú_Day20211025_09654.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/dataset/Chair_parsed/train/images/ÌÉÑÏ≤ú_Day20211125_02665.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /home/soma2/MVP/dataset/Chair_parsed/train/images/Ìè¥Î¶¨ÌÖçÎåÄÌïô_Day20211124_19519.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma2/MVP/dataset/Chair_parsed/val/labels.cache' images and\u001b[0m\n",
      "Plotting labels to runs/train/chair_l_0805/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.44 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/chair_l_0805\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/19      5.9G   0.08605   0.03162   0.06121         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.779     0.0367     0.0308     0.0108\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/19     6.83G   0.06329   0.02659   0.04304         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.677     0.0839     0.0627     0.0214\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/19     6.83G   0.06225    0.0259   0.03774         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.667     0.0425     0.0267    0.00919\n",
      "Current epoch : 2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/19     6.83G   0.06577   0.02714   0.03919         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.683     0.0808     0.0511     0.0169\n",
      "Current epoch : 3\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/19     6.83G   0.06271   0.02637   0.03593         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.764      0.117     0.0985     0.0391\n",
      "Current epoch : 4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/19     6.83G   0.05808   0.02549   0.03177         3       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.731      0.153      0.117     0.0469\n",
      "Current epoch : 5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/19     6.83G   0.05456   0.02467   0.02873         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.777      0.161       0.16     0.0673\n",
      "Current epoch : 6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/19     6.83G   0.05299   0.02423    0.0274         3       640: 100%|‚ñà‚ñà‚ñà\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.766       0.17      0.174     0.0795\n",
      "Current epoch : 7\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/19     6.83G   0.05106   0.02352   0.02501         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885       0.78      0.195      0.207     0.0938\n",
      "Current epoch : 8\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/19     6.83G   0.04862   0.02309   0.02333         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.777      0.228      0.241      0.114\n",
      "Current epoch : 9\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/19     6.83G   0.04676   0.02247   0.02138         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.749      0.238      0.237      0.111\n",
      "Current epoch : 10\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/19     6.83G   0.04725    0.0234   0.02264         3       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.757       0.22      0.227      0.111\n",
      "Current epoch : 11\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/19     6.83G   0.04592   0.02275    0.0209         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.799      0.261      0.279      0.142\n",
      "Current epoch : 12\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/19     6.83G   0.04364   0.02166   0.01859         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.809      0.257      0.291      0.155\n",
      "Current epoch : 13\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/19     6.83G   0.04253   0.02114   0.01786         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.744      0.279      0.322      0.177\n",
      "Current epoch : 14\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/19     6.83G   0.04029   0.02069    0.0163         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.833      0.289      0.336      0.188\n",
      "Current epoch : 15\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/19     6.83G   0.03887   0.02014   0.01518         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.807      0.314      0.364      0.209\n",
      "Current epoch : 16\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/19     6.83G    0.0373   0.01959   0.01398         3       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.705      0.346      0.376      0.224\n",
      "Current epoch : 17\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/19     6.83G   0.03583   0.01911   0.01305         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885       0.79      0.353      0.399      0.239\n",
      "Current epoch : 18\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/19     6.83G    0.0345   0.01876   0.01223         4       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.703      0.394      0.412      0.257\n",
      "Current epoch : 19\n",
      "\n",
      "20 epochs completed in 2.075 hours.\n",
      "Optimizer stripped from runs/train/chair_l_0805/weights/last.pt, 93.0MB\n",
      "Optimizer stripped from runs/train/chair_l_0805/weights/best.pt, 93.0MB\n",
      "\n",
      "Validating runs/train/chair_l_0805/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 367 layers, 46221363 parameters, 0 gradients, 108.0 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2237       4885      0.703      0.394      0.412      0.257\n",
      "       Leading Block       2237        200      0.741       0.69      0.728      0.455\n",
      "            baricade       2237       1038      0.603      0.713      0.688      0.447\n",
      "             bicycle       2237         88      0.328      0.682      0.622      0.387\n",
      "               bench       2237        302      0.569      0.672      0.669      0.385\n",
      "             bollard       2237        400      0.557      0.797       0.76      0.426\n",
      "                tree       2237        373      0.604      0.566      0.578      0.247\n",
      "          pedestrian       2237       1016      0.741      0.844      0.859      0.586\n",
      "            drainage       2237        352      0.613      0.662      0.644      0.395\n",
      "                 car       2237        282      0.463      0.774      0.689      0.512\n",
      "               truck       2237         71      0.458     0.0833      0.337      0.238\n",
      "                 bus       2237         29          1          0     0.0244     0.0178\n",
      "        traffic sign       2237          2          1          0          0          0\n",
      "             manhole       2237        297      0.753      0.646      0.691      0.453\n",
      "             labacon       2237        201      0.502      0.776      0.701      0.413\n",
      "       unusual bench       2237         18          1          0     0.0578     0.0445\n",
      "       Warning Block       2237         49       0.66      0.119       0.24       0.17\n",
      "               chair       2237          6          1          0   0.000367    0.00011\n",
      "     standing banner       2237          9          1          0     0.0125    0.00854\n",
      "                 pot       2237         78      0.632      0.309      0.463      0.284\n",
      "          wheelchair       2237          6          1          0    0.00231    0.00139\n",
      "           kickboard       2237         52      0.238      0.327       0.25       0.16\n",
      "          motorcycle       2237         16          1          0     0.0416     0.0233\n",
      "Results saved to \u001b[1mruns/train/chair_l_0805\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Chair large model init\n",
    "!python train.py --img 640 --name chair_l_0805 --rect --batch 16 --epochs 20 --data chair.yaml --weights wesee_l_v1.pt # --cfg yolov5l_wesee.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=wesee_l_v1.pt, cfg=, data=wesee.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=40, batch_size=16, imgsz=640, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=wesee_l_v2, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 üöÄ 2022-8-4 Python-3.7.2 torch-1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
      " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
      " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
      " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
      " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
      " 24      [17, 20, 23]  1     43080  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model summary: 468 layers, 46149064 parameters, 46149064 gradients, 108.3 GFLOPs\n",
      "\n",
      "Transferred 613/613 items from wesee_l_v1.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 101 weight (no decay), 104 weight, 104 bias\n",
      "WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/soma2/MVP/dataset/Wesee_parsed/train/labels' images and l\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/soma2/MVP/dataset/Wesee_parsed/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/soma2/MVP/dataset/Wesee_parsed/val/labels' images and label\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/soma2/MVP/dataset/Wesee_parsed/val/labels.cache\n",
      "Plotting labels to runs/train/wesee_l_v2/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.75 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/wesee_l_v2\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/39      5.9G   0.02349  0.005676  0.001159         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.877      0.914      0.921      0.659\n",
      "Current epoch : 0\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/39     6.82G   0.02505  0.005485  0.001094         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.854      0.896      0.912       0.63\n",
      "Current epoch : 1\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/39     6.82G    0.0285  0.006084  0.001432         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.831      0.833      0.849      0.543\n",
      "Current epoch : 2\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/39     6.83G   0.03055   0.00669   0.00186         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.848      0.846      0.876      0.584\n",
      "Current epoch : 3\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/39     6.83G   0.02847  0.006387  0.001535         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030       0.86      0.864      0.892      0.608\n",
      "Current epoch : 4\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/39     6.83G   0.02663  0.005941  0.001292         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.856      0.881      0.899      0.631\n",
      "Current epoch : 5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/39     6.83G   0.02519  0.005764  0.001205         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.874      0.861      0.903       0.64\n",
      "Current epoch : 6\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/39     6.83G   0.02441  0.005592  0.001178         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.888      0.907      0.924       0.68\n",
      "Current epoch : 7\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/39     6.83G   0.02363  0.005462  0.001136         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.878      0.891       0.92      0.669\n",
      "Current epoch : 8\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/39     6.83G   0.02319  0.005414  0.001057         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.891       0.89      0.924      0.689\n",
      "Current epoch : 9\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/39     6.83G   0.02279  0.005338  0.001107         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.885      0.904      0.933      0.698\n",
      "Current epoch : 10\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/39     6.83G   0.02213  0.005234  0.001015         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.881      0.906      0.933      0.708\n",
      "Current epoch : 11\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/39     6.83G   0.02156   0.00508  0.001009         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.915       0.94       0.72\n",
      "Current epoch : 12\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/39     6.83G   0.02096  0.005031  0.001087         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.885      0.922      0.939      0.721\n",
      "Current epoch : 13\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/39     6.83G   0.02116  0.005028  0.001115         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.885      0.916      0.939      0.719\n",
      "Current epoch : 14\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/39     6.83G   0.02059  0.004923  0.001055         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.891      0.925       0.94      0.728\n",
      "Current epoch : 15\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/39     6.83G   0.02019  0.004787  0.000838         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.887      0.927      0.944      0.733\n",
      "Current epoch : 16\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/39     6.83G   0.01977  0.004738  0.000885         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.888      0.919      0.942      0.734\n",
      "Current epoch : 17\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/39     6.83G   0.01967  0.004748 0.0008371         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.887      0.928      0.939      0.733\n",
      "Current epoch : 18\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/39     6.83G   0.01932   0.00464 0.0008284         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.883      0.945      0.945      0.738\n",
      "Current epoch : 19\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/39     6.83G   0.01929  0.004628 0.0008226         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.886      0.937      0.948      0.744\n",
      "Current epoch : 20\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/39     6.83G   0.01874  0.004512 0.0008338         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.891      0.932      0.947      0.749\n",
      "Current epoch : 21\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/39     6.83G   0.01838  0.004473  0.000754         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.898      0.929      0.945      0.749\n",
      "Current epoch : 22\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/39     6.83G   0.01815  0.004392 0.0007452         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.893      0.933      0.947       0.75\n",
      "Current epoch : 23\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/39     6.83G   0.01778  0.004386 0.0007432         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.898      0.929      0.949      0.754\n",
      "Current epoch : 24\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/39     6.83G   0.01755  0.004307  0.000715         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.905      0.924      0.949      0.756\n",
      "Current epoch : 25\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/39     6.83G   0.01718  0.004233 0.0007002         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.906      0.931       0.95      0.756\n",
      "Current epoch : 26\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/39     6.83G   0.01679  0.004173 0.0007101         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.905      0.934       0.95      0.757\n",
      "Current epoch : 27\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/39     6.83G   0.01668  0.004161 0.0006611         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.906      0.934      0.951       0.76\n",
      "Current epoch : 28\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/39     6.83G   0.01639  0.004114 0.0006877         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.904      0.936      0.949      0.761\n",
      "Current epoch : 29\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     30/39     6.83G    0.0161  0.004028 0.0006551         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.906      0.935       0.95      0.763\n",
      "Current epoch : 30\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     31/39     6.83G   0.01579  0.003946 0.0005986         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.904      0.937       0.95      0.763\n",
      "Current epoch : 31\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32/39     6.83G   0.01558  0.003946 0.0006427         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.901      0.938       0.95      0.764\n",
      "Current epoch : 32\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     33/39     6.83G   0.01522  0.003834 0.0006751         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.903      0.936       0.95      0.765\n",
      "Current epoch : 33\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     34/39     6.83G   0.01503  0.003784 0.0005852         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.905      0.936      0.951      0.766\n",
      "Current epoch : 34\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     35/39     6.83G   0.01465  0.003732 0.0005778         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.907      0.936      0.952      0.767\n",
      "Current epoch : 35\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     36/39     6.83G   0.01448  0.003675 0.0005869         2       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3594       5030      0.908      0.937      0.953      0.768\n",
      "Current epoch : 36\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     37/39     6.83G   0.01408   0.00356 0.0006037        20       640:  19%|‚ñà‚ñâ "
     ]
    }
   ],
   "source": [
    "# Chair large model init\n",
    "!python train.py --img 640 --name wesee_l_v2 --rect --batch 16 --epochs 40 --data wesee.yaml --weights wesee_l_v1.pt # --cfg yolov5l_wesee.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chair large model init\n",
    "!python train.py --img 640 --name chair_l_0805 --rect --batch 16 --epochs 60 --data chair.yaml --weights chair_l_v1.pt # --cfg yolov5l_wesee.yaml #--save-period 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 2. Validate\n",
    "Validate a model's accuracy on [COCO](https://cocodataset.org/#home) val or test-dev datasets. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "1434668c-e1de-43a4-fded-e91323452103"
   },
   "outputs": [],
   "source": [
    "# Wesee_80 val\n",
    "!python val.py --weights wesee_80.pt --data wesee.yaml --img 640 --iou 0.65 --half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 3. Inference\n",
    "\n",
    "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
    "\n",
    "```shell\n",
    "python detect.py --source 0  # webcam\n",
    "                          img.jpg  # image \n",
    "                          vid.mp4  # video\n",
    "                          path/  # directory\n",
    "                          path/*.jpg  # glob\n",
    "                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "zR9ZbuQCH7FX",
    "outputId": "a4dd083d-211f-4e81-aa1c-a263b330a719"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ../data/images\n",
    "display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Inference\n",
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ../data/images  --data ../data/coco128.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Inference\n",
    "!python detect.py --weights yolov5m.pt --img 640 --conf 0.25 --source ../data/images  --data ../data/coco128.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15glLzbQx5u0"
   },
   "source": [
    "# 4. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "## Weights & Biases Logging üåü NEW\n",
    "\n",
    "[Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_notebook) (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. To enable W&B `pip install wandb`, and then train normally (you will be guided through setup on first use). \n",
    "\n",
    "During training you will see live updates at [https://wandb.ai/home](https://wandb.ai/home?utm_campaign=repo_yolo_notebook), and you can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. For more information see the [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
    "\n",
    "<p align=\"left\"><img width=\"900\" alt=\"Weights & Biases dashboard\" src=\"https://user-images.githubusercontent.com/26833433/135390767-c28b050f-8455-4004-adb0-3b730386e2b2.png\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [],
   "source": [
    "# Tensorboard  (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fLAV42oNb7M"
   },
   "outputs": [],
   "source": [
    "# Weights & Biases  (optional)\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Appendix\n",
    "\n",
    "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcKoSIK2WSzj"
   },
   "outputs": [],
   "source": [
    "# Reproduce\n",
    "for x in 'yolov5n', 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x':\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --task speed  # speed\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMusP4OAxFu6"
   },
   "outputs": [],
   "source": [
    "# PyTorch Hub\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Images\n",
    "dir = 'https://ultralytics.com/images/'\n",
    "imgs = [dir + f for f in ('zidane.jpg', 'bus.jpg')]  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "results.print()  # or .show(), .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGH0ZjkGjejy"
   },
   "outputs": [],
   "source": [
    "# CI Checks\n",
    "%%shell\n",
    "export PYTHONPATH=\"$PWD\"  # to run *.py. files in subdirectories\n",
    "rm -rf runs  # remove runs/\n",
    "for m in yolov5n; do  # models\n",
    "  python train.py --img 64 --batch 32 --weights $m.pt --epochs 1 --device 0  # train pretrained\n",
    "  python train.py --img 64 --batch 32 --weights '' --cfg $m.yaml --epochs 1 --device 0  # train scratch\n",
    "  for d in 0 cpu; do  # devices\n",
    "    python val.py --weights $m.pt --device $d # val official\n",
    "    python val.py --weights runs/train/exp/weights/best.pt --device $d # val custom\n",
    "    python detect.py --weights $m.pt --device $d  # detect official\n",
    "    python detect.py --weights runs/train/exp/weights/best.pt --device $d  # detect custom\n",
    "  done\n",
    "  python hubconf.py  # hub\n",
    "  python models/yolo.py --cfg $m.yaml  # build PyTorch model\n",
    "  python models/tf.py --weights $m.pt  # build TensorFlow model\n",
    "  python export.py --img 64 --batch 1 --weights $m.pt --include torchscript onnx  # export\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gogI-kwi3Tye"
   },
   "outputs": [],
   "source": [
    "# Profile\n",
    "from utils.torch_utils import profile\n",
    "\n",
    "m1 = lambda x: x * torch.sigmoid(x)\n",
    "m2 = torch.nn.SiLU()\n",
    "results = profile(input=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVRSOhEvUdb5"
   },
   "outputs": [],
   "source": [
    "# Evolve\n",
    "!python train.py --img 640 --batch 64 --epochs 100 --data coco128.yaml --weights yolov5s.pt --cache --noautoanchor --evolve\n",
    "!d=runs/train/evolve && cp evolve.* $d && zip -r evolve.zip $d && gsutil mv evolve.zip gs://bucket  # upload results (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSgFCAcMbk1R"
   },
   "outputs": [],
   "source": [
    "# VOC\n",
    "for b, m in zip([64, 64, 64, 32, 16], ['yolov5n', 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x']):  # batch, model\n",
    "  !python train.py --batch {b} --weights {m}.pt --data VOC.yaml --epochs 50 --img 512 --hyp hyp.VOC.yaml --project VOC --name {m} --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTRwsvA9u7ln"
   },
   "outputs": [],
   "source": [
    "# TensorRT \n",
    "# https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-pip\n",
    "!pip install -U nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com  # install\n",
    "!python export.py --weights yolov5s.pt --include engine --imgsz 640 --device 0  # export\n",
    "!python detect.py --weights yolov5s.engine --imgsz 640 --device 0  # inference"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "YOLOv5 basic",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "037b09477fa14aa097d2b64af501ba03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13bc45f3b9c444a99c57325a6f59230e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bc42fbf6b6f44d6acb68612c70faa5f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a280c3595d7241fda184d93295b44a56",
      "value": " 780M/780M [00:07&lt;00:00, 130MB/s]"
     }
    },
    "1bc42fbf6b6f44d6acb68612c70faa5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "202a9fce8f2543efaaa2ed8c9d42d920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "207c4f4e92a04e79901d9acf83c9b446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_441f56ccb78e4a60b84212329e7adc51",
       "IPY_MODEL_94412b579e7048839e8af8f34c76b9e4",
       "IPY_MODEL_13bc45f3b9c444a99c57325a6f59230e"
      ],
      "layout": "IPY_MODEL_037b09477fa14aa097d2b64af501ba03"
     }
    },
    "35ea2fd621b147edbd26ca4954be998f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ba18e6a4d2f4949ab2bdf6b4f7ad59e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "441f56ccb78e4a60b84212329e7adc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ba18e6a4d2f4949ab2bdf6b4f7ad59e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f6e7b35f07e14dd3a41065669dd57b0c",
      "value": "100%"
     }
    },
    "578f046b1bc54c48b604fee25aca1035": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57b2d73efed0488b9d1748cd2d1e9b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6707a12a2ad947a2a7a347950623302d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72c229969ac84481a058279dafa1fdc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82f5601bd90b4ada9cec87011904e734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b4a53b9e0fd40018a5fc0672c16351e",
       "IPY_MODEL_f10ccba7201447608a079c5757cb6828",
       "IPY_MODEL_fefc249a1de64fd28eb7b32a9ce313a6"
      ],
      "layout": "IPY_MODEL_a4e252dbc8fb4b5aa681970c64210146"
     }
    },
    "94412b579e7048839e8af8f34c76b9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35ea2fd621b147edbd26ca4954be998f",
      "max": 818322941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57b2d73efed0488b9d1748cd2d1e9b9d",
      "value": 818322941
     }
    },
    "9b4a53b9e0fd40018a5fc0672c16351e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b04963a9b74e4451a525f81c4768c295",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_202a9fce8f2543efaaa2ed8c9d42d920",
      "value": "100%"
     }
    },
    "a280c3595d7241fda184d93295b44a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4e252dbc8fb4b5aa681970c64210146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b04963a9b74e4451a525f81c4768c295": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ce35d2764a43cf949765a3d499eba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f10ccba7201447608a079c5757cb6828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72c229969ac84481a058279dafa1fdc1",
      "max": 71005511,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6707a12a2ad947a2a7a347950623302d",
      "value": 71005511
     }
    },
    "f6e7b35f07e14dd3a41065669dd57b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fefc249a1de64fd28eb7b32a9ce313a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_578f046b1bc54c48b604fee25aca1035",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e5ce35d2764a43cf949765a3d499eba8",
      "value": " 67.7M/67.7M [00:00&lt;00:00, 110MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
