{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17c84b5",
   "metadata": {},
   "source": [
    "# Run YOLOv7 on Cloud GPU\n",
    "\n",
    "YOLOV7 is the latest edition of popular YOLO algorithm specifically designed for industry applications. It achieves high mAP with amazing fps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306ea83",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/WongKinYiu/yolov7.git\n",
    "cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad12346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soma2/MVP/voyager-Vision-task/my_yolov7\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7e34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu110 in /home/soma2/anaconda3/lib/python3.8/site-packages (1.7.1+cu110)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu110 in /home/soma2/anaconda3/lib/python3.8/site-packages (0.8.2+cu110)\n",
      "Requirement already satisfied: numpy in /home/soma2/anaconda3/lib/python3.8/site-packages (from torch==1.7.1+cu110) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /home/soma2/anaconda3/lib/python3.8/site-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from torchvision==0.8.2+cu110) (8.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 4)) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 5)) (1.20.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 6)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 7)) (8.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 9)) (2.25.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 10)) (1.6.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 15)) (4.59.0)\n",
      "Requirement already satisfied: protobuf<4.21.3 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 16)) (3.19.4)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 19)) (2.9.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 23)) (1.2.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 24)) (0.11.1)\n",
      "Requirement already satisfied: ipython in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 36)) (7.22.0)\n",
      "Requirement already satisfied: psutil in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 37)) (5.8.0)\n",
      "Requirement already satisfied: thop in /home/soma2/anaconda3/lib/python3.8/site-packages (from -r my_requirements.txt (line 38)) (0.1.0.post2207010342)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/soma2/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/soma2/anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/soma2/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soma2/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/soma2/anaconda3/lib/python3.8/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (1.47.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/soma2/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (3.3.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/soma2/anaconda3/lib/python3.8/site-packages (from pandas>=1.1.4->-r my_requirements.txt (line 23)) (2021.1)\n",
      "Requirement already satisfied: pygments in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (2.8.1)\n",
      "Requirement already satisfied: decorator in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (5.0.6)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (5.0.5)\n",
      "Requirement already satisfied: backcall in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from ipython->-r my_requirements.txt (line 36)) (3.0.17)\n",
      "Requirement already satisfied: torch in /home/soma2/anaconda3/lib/python3.8/site-packages (from thop->-r my_requirements.txt (line 38)) (1.7.1+cu110)\n",
      "Requirement already satisfied: six in /home/soma2/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/soma2/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/soma2/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (1.3.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython->-r my_requirements.txt (line 36)) (0.7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/soma2/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (4.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/soma2/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython->-r my_requirements.txt (line 36)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/soma2/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r my_requirements.txt (line 36)) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /home/soma2/anaconda3/lib/python3.8/site-packages (from traitlets>=4.2->ipython->-r my_requirements.txt (line 36)) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/soma2/anaconda3/lib/python3.8/site-packages (from torch->thop->-r my_requirements.txt (line 38)) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/soma2/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/soma2/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/soma2/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "%pip install -r my_requirements.txt  # install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885bc66",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcc30127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ v0.1-79-gcc42a20 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp7', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='yolov7.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n",
      "\n",
      "Transferred 558/566 items from yolov7.pt\n",
      "\n",
      "WARNING: Dataset not found, nonexistent paths: ['/home/soma2/MVP/yolov7/coco/val2017.txt']\n",
      "Downloading bash ./scripts/get_coco.sh ...\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip  ...\n",
      "Downloading http://images.cocodataset.org/zips/train2017.zip ...\n",
      "Downloading http://images.cocodataset.org/zips/val2017.zip ...\n",
      "Downloading http://images.cocodataset.org/zips/test2017.zip ...\n",
      "        %%%%    TTTToooottttaaaallll                %%%%    ReRRRceeececcieeievivievevdede d d% %  % %XX  ffXXeeffrreeddrr  dd    AA  AvvvAeeevrrreaaargggaeeeg   eSSS pppSeeepeeeeddde   d      T  TiT imiTmemie em   e         T  TiT imiTmemie em   e             Ti  TmT ieiTm  mieCeme u   r  CrCCueuurnrrrterr\n",
      "nee tnn \n",
      "tt  \n",
      "\n",
      "                                                                                                                       D  Dl  lo  oa  add  D D l UloadUop pal ldoUo apa dd lU  op  al TdoTo aot dta  alT l o   tT  ao Slt Spae pln e tSn  pt  e  Sn  ptL e e n fLt te   f L t eS  fp Lte eSe dpfS\n",
      " de  \n",
      "d S\n",
      " e   e0  d    0 \n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0   0     00            00             00        00                  0 00    -0- - - :-: --- -::- --:0--- : ---- ----: :----:----::-:---:----  :---- ----:: ----:----:::----:----  :-- - - -  :   - 0 -  : 0- -0     0\n",
      "100  167M  100  167M    0     0  8092k      0  0:00:21  0:00:21 --:--:-- 8848k\n",
      "100  777M  100  777M    0     0  2576k      0  0:05:09  0:05:09 --:--:-- 2912k: 4 3 : 4 90  3 800:73k1:44  0:03:30  0:28:14 3903k4:24 3402k   0     0  2452k      0  0:05:24  0:03:32  0:01:52 3163k   0  3588k      0  0:30:08  0:04:35  0:25:33 4106k     0  3610k      0  0:29:57  0:05:06  0:24:51 3425k\n",
      "100 6339M  100 6339M    0     0  4136k      0  0:26:09  0:26:09 --:--:-- 3014k0:58:08  0:25:04  0:33:04 7579k 0:36:48 1102k7:38  1:12:00 5856k:08:09  1:07:58 7404k5925k 0     0  4267k      0  0:25:20  0:17:25  0:07:55 3940k:53  0:19:04  0:39:49 6843k5034M    0     0  4230k      0  0:25:34  0:20:18  0:05:16 5997k5406k\n",
      "100 18.0G  100 18.0G    0     0  6137k      0  0:51:16  0:51:16 --:--:-- 8589k:31:16  0:24:06 8680k  0:54:04  0:35:40  0:18:24 6067k     0  5871k      0  0:53:36  0:37:02  0:16:34 5681k      0  0:53:08  0:39:40  0:13:28 6155k0  0:53:13  0:39:55  0:13:18 5297k   0     0  5923k      0  0:53:07  0:40:40  0:12:27 7411k   0  0:52:31  0:45:28  0:07:03 7992k0  0:52:28  0:45:37  0:06:51 7698k\n",
      "Dataset autodownload success\n",
      "\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017' images and labels... 117266 found, 1021 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: coco/train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017' images and labels... 4952 found, 48 missing, 0 empt\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: coco/val2017.cache\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.42, Best Possible Recall (BPR) = 0.9911\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp7\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       0/2     12.1G   0.03983   0.03906   0.07399    0.1529       282       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335        0.71       0.603       0.649       0.448\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       1/2     22.8G   0.02666   0.02806   0.00978    0.0645       297       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335       0.699       0.585       0.633       0.438\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       2/2     22.8G   0.02531   0.02804  0.009515   0.06287       221       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335       0.678       0.609       0.642        0.45\n",
      "3 epochs completed in 3.062 hours.\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36907898 parameters, 6194944 gradients, 104.5 GFLOPS\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335         0.7       0.587       0.636       0.447\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/train/exp7/_predictions.json...\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36907898 parameters, 6194944 gradients, 104.5 GFLOPS\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335         0.7       0.587       0.636       0.447\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/train/exp7/_predictions.json...\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Optimizer stripped from runs/train/exp7/weights/last.pt, 75.6MB\n",
      "Optimizer stripped from runs/train/exp7/weights/best.pt, 75.6MB\n"
     ]
    }
   ],
   "source": [
    "# train p5 models\n",
    "!python train.py --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights yolov7.pt --hyp data/hyp.scratch.p5.yaml --epoch 3\n",
    "\n",
    "# train p6 models\n",
    "# python train_aux.py --workers 8 --device 0 --batch-size 16 --data data/coco.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6.yaml --weights '' --name yolov7-w6 --hyp data/hyp.scratch.p6.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a09222ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 84fc650 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/wesee.yaml', device='', entity=None, epochs=50, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp12', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='yolov7.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1     44944  models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37207344 parameters, 37207344 gradients, 105.1 GFLOPS\n",
      "\n",
      "Transferred 552/566 items from yolov7.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../../dataset/Wesee_parsed/train/labels' images and labels... 2\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../../dataset/Wesee_parsed/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../../dataset/Wesee_parsed/val/labels' images and labels... 3594 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../../dataset/Wesee_parsed/val/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.84, Best Possible Recall (BPR) = 0.9943\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp12\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      0/49       12G   0.04883   0.06547    0.0115    0.1258         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.599       0.769       0.717       0.442\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      1/49     21.8G   0.02723  0.004998  0.001004   0.03323        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.866       0.867        0.89       0.601\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      2/49     21.8G   0.02604  0.005049 0.0006747   0.03176         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.849       0.852       0.883       0.596\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      3/49     21.8G    0.0242  0.005009 0.0005872   0.02979        15       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.847       0.895       0.896       0.622\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      4/49     21.8G   0.02219   0.00473 0.0005381   0.02746         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.887       0.887       0.914       0.664\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      5/49     21.8G   0.02129  0.004635 0.0005049   0.02643         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.896       0.899       0.932       0.685\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      6/49     21.8G   0.02058  0.004522  0.000452   0.02555         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.886       0.918       0.932       0.695\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      7/49     21.8G   0.01984  0.004493 0.0004537   0.02479         3       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.887       0.923        0.93       0.698\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      8/49     21.8G   0.01958  0.004401 0.0004244    0.0244         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.868       0.924       0.926       0.709\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      9/49     21.8G   0.01918  0.004379 0.0004403     0.024         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.896       0.925       0.935       0.715\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     10/49     21.8G   0.01884  0.004321 0.0004552   0.02362         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.883       0.933       0.946        0.73\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     11/49     21.8G   0.01851  0.004253  0.000422   0.02318         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.891       0.927       0.942       0.733\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     12/49     21.8G   0.01842  0.004223 0.0004408   0.02308         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.892       0.926       0.946       0.739\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     13/49     21.8G   0.01825  0.004206 0.0004158   0.02287         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.898       0.923       0.947       0.741\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     14/49     21.8G   0.01788   0.00411 0.0004123    0.0224         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.899        0.92       0.948       0.747\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     15/49     21.8G   0.01769  0.004148 0.0003909   0.02222         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.923       0.951       0.748\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     16/49     21.8G   0.01755  0.004114 0.0003898   0.02206        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030        0.88       0.947        0.95       0.754\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     17/49     21.8G   0.01731  0.004083 0.0004054    0.0218         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.915       0.912       0.945       0.754\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     18/49     21.8G   0.01711  0.004027 0.0003652   0.02151         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.899       0.934       0.952       0.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     19/49     21.8G     0.017   0.00399 0.0003641   0.02136         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.888        0.95       0.953       0.762\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     20/49     21.8G   0.01677   0.00398 0.0003738   0.02113        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.901       0.942       0.953       0.763\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     21/49     21.8G   0.01664  0.003997 0.0003508   0.02099        16       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.901       0.941       0.956       0.768\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     22/49     21.8G   0.01646  0.003908  0.000366   0.02074        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.909       0.937       0.955       0.768\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     23/49     21.8G   0.01634  0.003891 0.0003617   0.02059        14       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.902       0.943       0.955       0.769\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     24/49     21.8G    0.0161  0.003829 0.0003752   0.02031        12       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.911       0.934       0.957       0.773\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     25/49     21.8G   0.01599  0.003865 0.0003601   0.02022         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912       0.935       0.957       0.773\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     26/49     21.8G   0.01583  0.003837  0.000375   0.02004         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912       0.939       0.958       0.775\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     27/49     21.8G   0.01565  0.003842 0.0003649   0.01986         9       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.913       0.937       0.959       0.777\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     28/49     21.8G    0.0155  0.003796 0.0003445   0.01964        18       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.946        0.96       0.778\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     29/49     21.8G   0.01534  0.003747 0.0003413   0.01943         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.905       0.947        0.96       0.779\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     30/49     21.8G   0.01518  0.003674 0.0003498   0.01921         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912       0.941       0.961        0.78\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     31/49     21.8G   0.01496  0.003703 0.0003496   0.01901         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912        0.94       0.958       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     32/49     21.8G   0.01486  0.003656 0.0003401   0.01885         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.909       0.948       0.961       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     33/49     21.8G    0.0147  0.003612 0.0003457   0.01866        13       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.913       0.943       0.961       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     34/49     21.8G   0.01455  0.003582 0.0003292   0.01846         3       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.906       0.949       0.962       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     35/49     21.8G   0.01447  0.003579 0.0003215   0.01837         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.953       0.961       0.783\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     36/49     21.8G   0.01436  0.003566 0.0003185   0.01824         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.954       0.962       0.783\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     37/49     21.8G    0.0142   0.00351 0.0003003   0.01801         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.918       0.938       0.963       0.784\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     38/49     21.8G   0.01409  0.003512 0.0002949   0.01789         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.919       0.938       0.962       0.786\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     39/49     21.8G   0.01394  0.003461 0.0003215   0.01772        15       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.921       0.938       0.962       0.786\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     40/49     21.8G   0.01382  0.003448 0.0003178   0.01758         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030        0.92       0.938       0.963       0.787\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     41/49     21.8G   0.01372  0.003407 0.0003004   0.01743         3       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.924       0.935       0.963       0.786\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     42/49     21.8G   0.01356  0.003406 0.0002991   0.01726         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.939       0.963       0.787\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     43/49     21.8G   0.01355  0.003379 0.0003117   0.01724        11       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.939       0.963       0.787\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     44/49     21.8G   0.01338  0.003332 0.0002897     0.017        11       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.939       0.964       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     45/49     21.8G   0.01331  0.003326 0.0002997   0.01693        13       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.923       0.938       0.963       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     46/49     21.8G   0.01326  0.003307 0.0003252   0.01689         2       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.923       0.938       0.963       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     47/49     21.8G   0.01328   0.00332 0.0003186   0.01692        13       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.924       0.937       0.963       0.789\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     48/49     21.8G   0.01327  0.003295 0.0002931   0.01686         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.938       0.963       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     49/49     21.8G   0.01315  0.003285 0.0003077   0.01674         9       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922        0.94       0.963       0.789\n",
      "         Zebra_Cross        3594        3619       0.981       0.962        0.99       0.938\n",
      "            R_Signal        3594        1021       0.885       0.937       0.954        0.72\n",
      "            G_Signal        3594         390         0.9        0.92       0.946       0.708\n",
      "50 epochs completed in 11.862 hours.\n",
      "\n",
      "Optimizer stripped from runs/train/exp12/weights/last.pt, 74.8MB\n",
      "Optimizer stripped from runs/train/exp12/weights/best.pt, 74.8MB\n"
     ]
    }
   ],
   "source": [
    "# Wesee Init Training\n",
    "!python train.py --batch-size 32 --epoch 50 --data data/wesee.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights yolov7.pt # --hyp data/hyp.scratch.p5.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b24505",
   "metadata": {},
   "source": [
    "# 2. Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb35217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a872fc39",
   "metadata": {},
   "source": [
    "# 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81a41bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/images/horses.jpg', update=False, view_img=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ v0.1-79-gcc42a20 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to yolov7.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.1M/72.1M [00:06<00:00, 11.2MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients, 104.5 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      " The image with the result is saved in: runs/detect/exp/horses.jpg\n",
      "Done. (0.032s)\n"
     ]
    }
   ],
   "source": [
    "# My Inference test\n",
    "!python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6f4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.5, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/test', update=False, view_img=False, weights=['wesee.pt'])\n",
      "YOLOR ðŸš€ 84fc650 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      " The image with the result is saved in: runs/detect/exp4/MP_KSC_005400.jpg\n",
      " The image with the result is saved in: runs/detect/exp4/MP_KSC_005528.jpg\n",
      " The image with the result is saved in: runs/detect/exp4/MP_KSC_005529.jpg\n",
      "Done. (0.051s)\n"
     ]
    }
   ],
   "source": [
    "# Inference time test\n",
    "!python detect.py --weights wesee.pt --conf 0.5 --img-size 640 --source inference/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12181e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/sample', update=False, view_img=False, weights=['wesee.pt'])\n",
      "YOLOR ðŸš€ 72927ac torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_000328.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_000385.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_000684.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001103.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001131.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001142.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001244.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001389.jpg\n",
      "Done. (0.127s)\n"
     ]
    }
   ],
   "source": [
    "# Inference time test\n",
    "!python detect.py --weights wesee.pt --conf 0.3 --img-size 640 --source inference/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915ec476",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d4ecf4a907e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./inference/images/horses.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mreslut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "model = torch.load(\"./wesee.pt\")\n",
    "path = './inference/images/horses.jpg'\n",
    "img = Image.open(path)\n",
    "result = model(img)\n",
    "reslut.print()\n",
    "result.pandas().xyxy[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f99b4",
   "metadata": {},
   "source": [
    "# 3.1 Advanced Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe9b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e75114",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_filter = ['train']\n",
    "opt  = {\n",
    "    \n",
    "    \"weights\": \"weights/yolov7.pt\", # Path to weights file default weights are for nano model\n",
    "    \"yaml\"   : \"data/coco.yaml\",\n",
    "    \"img-size\": 640, # default image size\n",
    "    \"conf-thres\": 0.25, # confidence threshold for inference.\n",
    "    \"iou-thres\" : 0.45, # NMS IoU threshold for inference.\n",
    "    \"device\" : '0',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
    "    \"classes\" : classes_to_filter  # list of classes to filter or None\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c497b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ v0.1-79-gcc42a20 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to weights/yolov7.pt...\n",
      "Download error: [Errno 2] No such file or directory: 'weights/tmpnmoa1wca'\n",
      "ERROR: Download failure: weights/yolov7.pt missing, try downloading from https://github.com/WongKinYiu/yolov7/releases/\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weights/yolov7.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c65afd379094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mhalf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_img_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check img_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MVP/yolov7/models/experimental.py\u001b[0m in \u001b[0;36mattempt_load\u001b[0;34m(weights, map_location)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mattempt_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ema'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ema'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights/yolov7.pt'"
     ]
    }
   ],
   "source": [
    "# Give path of source image\n",
    "source_image_path = 'inference/images/horses.jpg'\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  img0 = cv2.imread(source_image_path)\n",
    "  img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "  img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "  img = np.ascontiguousarray(img)\n",
    "  img = torch.from_numpy(img).to(device)\n",
    "  img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "  img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "  if img.ndimension() == 3:\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "  # Inference\n",
    "  t1 = time_synchronized()\n",
    "  pred = model(img, augment= False)[0]\n",
    "\n",
    "  # Apply NMS\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "\n",
    "      classes.append(names.index(class_name))\n",
    "\n",
    "  if classes:\n",
    "    \n",
    "    classes = [i for i in range(len(names)) if i not in classes]\n",
    "  \n",
    "  \n",
    "  pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= [17], agnostic= False)\n",
    "  t2 = time_synchronized()\n",
    "  for i, det in enumerate(pred):\n",
    "    s = ''\n",
    "    s += '%gx%g ' % img.shape[2:]  # print string\n",
    "    gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "    if len(det):\n",
    "      det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "      for c in det[:, -1].unique():\n",
    "        n = (det[:, -1] == c).sum()  # detections per class\n",
    "        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "    \n",
    "      for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "        label = f'{names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714d302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
