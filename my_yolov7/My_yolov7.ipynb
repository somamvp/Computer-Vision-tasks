{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run YOLOv7 on Cloud GPU\n",
    "\n",
    "YOLOV7 is the latest edition of popular YOLO algorithm specifically designed for industry applications. It achieves high mAP with amazing fps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/WongKinYiu/yolov7.git\n",
    "cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soma2/MVP/voyager-Vision-task/my_yolov7\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.1+cu110\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1156.8MB 86kB/s s eta 0:00:01    |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 560.0MB 10.9MB/s eta 0:00:55     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 650.6MB 8.9MB/s eta 0:00:57     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 741.4MB 10.7MB/s eta 0:00:39\n",
      "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.9MB 12.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/soma1/anaconda3/lib/python3.7/site-packages (from torch==1.7.1+cu110) (1.17.2)\n",
      "Collecting typing-extensions (from torch==1.7.1+cu110)\n",
      "  Using cached https://files.pythonhosted.org/packages/ed/d6/2afc375a8d55b8be879d6b4986d4f69f01115e795e36827fd3a40166028b/typing_extensions-4.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/soma1/anaconda3/lib/python3.7/site-packages (from torchvision==0.8.2+cu110) (6.2.0)\n",
      "Installing collected packages: typing-extensions, torch, torchvision\n",
      "Successfully installed torch-1.7.1+cu110 torchvision-0.8.2+cu110 typing-extensions-4.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib>=3.2.2 (from -r my_requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/62/7b662284352867a86acfb636761ba351723fc3a235efd8397578d903413d/matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.2MB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.18.5 (from -r my_requirements.txt (line 5))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/ad/ff3b21ebfe79a4d25b4a4f8e5cf9fd44a204adb6b33c09010f566f51027a/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.7MB 12.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python>=4.1.1 (from -r my_requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/7a/1c/e57fe138615c29b8d1442009057dd420c58d4773cb16112e914c9e7b47d8/opencv-python-4.6.0.66.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Pillow>=7.1.2 (from -r my_requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/92/2975b464d9926dc667020ed1abfa6276e68c3571dcb77e43347e15ee9eed/Pillow-9.2.0.tar.gz (50.0MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50.0MB 10.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML>=5.3.1 (from -r my_requirements.txt (line 8))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 604kB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.23.0 (from -r my_requirements.txt (line 9))\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/91/6d9b8ccacd0412c08820f72cebaa4f0c0441b5cda699c90f618b6f8a1b42/requests-2.28.1-py3-none-any.whl\n",
      "Collecting scipy>=1.4.1 (from -r my_requirements.txt (line 10))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/4f/11f34cfc57ead25752a7992b069c36f5d18421958ebd6466ecd849aeaf86/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.1MB 10.4MB/s eta 0:00:01     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 19.3MB 11.7MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting tqdm>=4.41.0 (from -r my_requirements.txt (line 15))\n",
      "  Using cached https://files.pythonhosted.org/packages/47/bb/849011636c4da2e44f1253cd927cfb20ada4374d8b3a4e425416e84900cc/tqdm-4.64.1-py2.py3-none-any.whl\n",
      "Collecting protobuf<4.21.3 (from -r my_requirements.txt (line 16))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/c0/22644cfa509d520e797a7c5774dbbf70543e4c03bea087f4976d020b7b38/protobuf-4.21.2-py2.py3-none-any.whl (164kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 10.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard>=2.4.1 (from -r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/6b/42/e271c40c84c250b52fa460fda970899407c837a2049c53969f37e404b1f6/tensorboard-2.10.0-py3-none-any.whl\n",
      "Collecting pandas>=1.1.4 (from -r my_requirements.txt (line 23))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/f0/f99700ef327e51d291efdf4a6de29e685c4d198cbf8531541fc84d169e0e/pandas-1.3.5.tar.gz (4.7MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.7MB 11.0MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting seaborn>=0.11.0 (from -r my_requirements.txt (line 24))\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/03/14991c1f18422eb640f6fe6eadf9a675bb21d9339236d64c3d12bd0eb1a4/seaborn-0.12.0-py3-none-any.whl\n",
      "Requirement already satisfied: ipython in /home/soma1/anaconda3/lib/python3.7/site-packages (from -r my_requirements.txt (line 36)) (7.8.0)\n",
      "Requirement already satisfied: psutil in /home/soma1/anaconda3/lib/python3.7/site-packages (from -r my_requirements.txt (line 37)) (5.6.3)\n",
      "Collecting thop (from -r my_requirements.txt (line 38))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/0f/72beeab4ff5221dc47127c80f8834b4bcd0cb36f6ba91c0b1d04a1233403/thop-0.1.1.post2209072238-py3-none-any.whl\n",
      "Collecting packaging>=20.0 (from matplotlib>=3.2.2->-r my_requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/05/8e/8de486cbd03baba4deef4142bd643a3e7bbe954a784dc1bb17142572d127/packaging-21.3-py3-none-any.whl\n",
      "Requirement already satisfied: cycler>=0.10 in /home/soma1/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/soma1/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/soma1/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (1.1.0)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.2.2->-r my_requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/1c/ed3d02ee49952bab33318269bbc316cde6b92205ca77224e558de76f1cd6/fonttools-4.37.3-py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/soma1/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (2.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soma1/anaconda3/lib/python3.7/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soma1/anaconda3/lib/python3.7/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soma1/anaconda3/lib/python3.7/site-packages (from requests>=2.23.0->-r my_requirements.txt (line 9)) (2019.9.11)\n",
      "Collecting charset-normalizer<3,>=2 (from requests>=2.23.0->-r my_requirements.txt (line 9))\n",
      "  Using cached https://files.pythonhosted.org/packages/db/51/a507c856293ab05cdc1db77ff4bc1268ddd39f29e7dc4919aa497f0adbec/charset_normalizer-2.1.1-py3-none-any.whl\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/a5/b8/fc74a554a6fc7f26744c883ebfe405cf49c1f1320f13ee874aee47c70e1d/absl_py-1.2.0-py3-none-any.whl\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/27/be6ddbcf60115305205de79c29004a0c6bc53cec814f733467b1bb89386d/Werkzeug-2.2.2-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://files.pythonhosted.org/packages/86/be/ad281f7a3686b38dd8a307fa33210cdf2130404dfef668a37a4166d737ca/Markdown-3.4.1-py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/b1/0e/0636cc1448a7abc444fb1b3a63655e294e0d2d49092dc3de05241be6d43c/google_auth_oauthlib-0.4.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/soma1/anaconda3/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (41.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/soma1/anaconda3/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.33.6)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/be/65/3126b832ae3a8c7446820a9603b4b73e39ade43995922665f128f5aa53ab/google_auth-2.11.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/68/e8ecfac5dd594b676c23a7f07ea34c197d7d69b3313afdf8ac1b0a9905a2/tensorboard_plugin_wit-1.8.1-py3-none-any.whl\n",
      "Collecting grpcio>=1.24.3 (from tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/1c/c42834d4fee45c5cf2d9546e97e879a1cbcdecfd16eb1a12144dcb91edae/grpcio-1.49.1.tar.gz (22.1MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.1MB 10.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /home/soma1/anaconda3/lib/python3.7/site-packages (from pandas>=1.1.4->-r my_requirements.txt (line 23)) (2019.3)\n",
      "Requirement already satisfied: typing_extensions; python_version < \"3.8\" in /home/soma1/anaconda3/lib/python3.7/site-packages (from seaborn>=0.11.0->-r my_requirements.txt (line 24)) (4.3.0)\n",
      "Requirement already satisfied: pickleshare in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (4.3.3)\n",
      "Requirement already satisfied: backcall in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (0.1.0)\n",
      "Requirement already satisfied: decorator in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (4.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (2.0.10)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (0.15.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (4.7.0)\n",
      "Requirement already satisfied: pygments in /home/soma1/anaconda3/lib/python3.7/site-packages (from ipython->-r my_requirements.txt (line 36)) (2.4.2)\n",
      "Requirement already satisfied: torch in /home/soma1/anaconda3/lib/python3.7/site-packages (from thop->-r my_requirements.txt (line 38)) (1.7.1+cu110)\n",
      "Requirement already satisfied: six in /home/soma1/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.2.2->-r my_requirements.txt (line 4)) (1.12.0)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/97/2288fe498044284f39ab8950703e88abbac2abbdf65524d576157af70556/MarkupSafe-2.1.1.tar.gz\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\" (from markdown>=2.6.8->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/a2/8c239dc898138f208dd14b441b196e7b3032b94d3137d9d8453e186967fc/importlib_metadata-4.12.0-py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/bb/5deac77a9af870143c684ab46a7934038a53eb4aa975bc0687ed6ca2c610/requests_oauthlib-1.3.1-py2.py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\" (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/68/aa/5fc646cae6e997c3adf3b0a7e257cda75cff21fcba15354dffd67789b7bb/cachetools-5.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: ipython-genutils in /home/soma1/anaconda3/lib/python3.7/site-packages (from traitlets>=4.2->ipython->-r my_requirements.txt (line 36)) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /home/soma1/anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r my_requirements.txt (line 36)) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.5.0 in /home/soma1/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->-r my_requirements.txt (line 36)) (0.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/soma1/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->-r my_requirements.txt (line 36)) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/soma1/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (0.6.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/bb/d669baf53d4ffe081dab80aad93c5c79f84eeac885dd31507c8c055a98d5/oauthlib-3.2.1-py3-none-any.whl (151kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 11.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r my_requirements.txt (line 19))\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: more-itertools in /home/soma1/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard>=2.4.1->-r my_requirements.txt (line 19)) (7.2.0)\n",
      "Building wheels for collected packages: opencv-python, pandas\n",
      "  Building wheel for opencv-python (PEP 517) ... \u001b[?25l\\"
     ]
    }
   ],
   "source": [
    "# %pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "%pip install -r my_requirements.txt  # install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ v0.1-79-gcc42a20 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/coco.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp7', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='yolov7.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n",
      "\n",
      "Transferred 558/566 items from yolov7.pt\n",
      "\n",
      "WARNING: Dataset not found, nonexistent paths: ['/home/soma2/MVP/yolov7/coco/val2017.txt']\n",
      "Downloading bash ./scripts/get_coco.sh ...\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip  ...\n",
      "Downloading http://images.cocodataset.org/zips/train2017.zip ...\n",
      "Downloading http://images.cocodataset.org/zips/val2017.zip ...\n",
      "Downloading http://images.cocodataset.org/zips/test2017.zip ...\n",
      "        %%%%    TTTToooottttaaaallll                %%%%    ReRRRceeececcieeievivievevdede d d% %  % %XX  ffXXeeffrreeddrr  dd    AA  AvvvAeeevrrreaaargggaeeeg   eSSS pppSeeepeeeeddde   d      T  TiT imiTmemie em   e         T  TiT imiTmemie em   e             Ti  TmT ieiTm  mieCeme u   r  CrCCueuurnrrrterr\n",
      "nee tnn \n",
      "tt  \n",
      "\n",
      "                                                                                                                       D  Dl  lo  oa  add  D D l UloadUop pal ldoUo apa dd lU  op  al TdoTo aot dta  alT l o   tT  ao Slt Spae pln e tSn  pt  e  Sn  ptL e e n fLt te   f L t eS  fp Lte eSe dpfS\n",
      " de  \n",
      "d S\n",
      " e   e0  d    0 \n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0   0     00            00             00        00                  0 00    -0- - - :-: --- -::- --:0--- : ---- ----: :----:----::-:---:----  :---- ----:: ----:----:::----:----  :-- - - -  :   - 0 -  : 0- -0     0\n",
      "100  167M  100  167M    0     0  8092k      0  0:00:21  0:00:21 --:--:-- 8848k\n",
      "100  777M  100  777M    0     0  2576k      0  0:05:09  0:05:09 --:--:-- 2912k: 4 3 : 4 90  3 800:73k1:44  0:03:30  0:28:14 3903k4:24 3402k   0     0  2452k      0  0:05:24  0:03:32  0:01:52 3163k   0  3588k      0  0:30:08  0:04:35  0:25:33 4106k     0  3610k      0  0:29:57  0:05:06  0:24:51 3425k\n",
      "100 6339M  100 6339M    0     0  4136k      0  0:26:09  0:26:09 --:--:-- 3014k0:58:08  0:25:04  0:33:04 7579k 0:36:48 1102k7:38  1:12:00 5856k:08:09  1:07:58 7404k5925k 0     0  4267k      0  0:25:20  0:17:25  0:07:55 3940k:53  0:19:04  0:39:49 6843k5034M    0     0  4230k      0  0:25:34  0:20:18  0:05:16 5997k5406k\n",
      "100 18.0G  100 18.0G    0     0  6137k      0  0:51:16  0:51:16 --:--:-- 8589k:31:16  0:24:06 8680k  0:54:04  0:35:40  0:18:24 6067k     0  5871k      0  0:53:36  0:37:02  0:16:34 5681k      0  0:53:08  0:39:40  0:13:28 6155k0  0:53:13  0:39:55  0:13:18 5297k   0     0  5923k      0  0:53:07  0:40:40  0:12:27 7411k   0  0:52:31  0:45:28  0:07:03 7992k0  0:52:28  0:45:37  0:06:51 7698k\n",
      "Dataset autodownload success\n",
      "\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017' images and labels... 117266 found, 1021 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: coco/train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017' images and labels... 4952 found, 48 missing, 0 empt\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: coco/val2017.cache\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.42, Best Possible Recall (BPR) = 0.9911\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp7\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       0/2     12.1G   0.03983   0.03906   0.07399    0.1529       282       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335        0.71       0.603       0.649       0.448\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       1/2     22.8G   0.02666   0.02806   0.00978    0.0645       297       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335       0.699       0.585       0.633       0.438\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "       2/2     22.8G   0.02531   0.02804  0.009515   0.06287       221       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335       0.678       0.609       0.642        0.45\n",
      "3 epochs completed in 3.062 hours.\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36907898 parameters, 6194944 gradients, 104.5 GFLOPS\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335         0.7       0.587       0.636       0.447\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/train/exp7/_predictions.json...\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36907898 parameters, 6194944 gradients, 104.5 GFLOPS\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        5000       36335         0.7       0.587       0.636       0.447\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs/train/exp7/_predictions.json...\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Optimizer stripped from runs/train/exp7/weights/last.pt, 75.6MB\n",
      "Optimizer stripped from runs/train/exp7/weights/best.pt, 75.6MB\n"
     ]
    }
   ],
   "source": [
    "# train p5 models\n",
    "!python train.py --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights yolov7.pt --hyp data/hyp.scratch.p5.yaml --epoch 3\n",
    "\n",
    "# train p6 models\n",
    "# python train_aux.py --workers 8 --device 0 --batch-size 16 --data data/coco.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6.yaml --weights '' --name yolov7-w6 --hyp data/hyp.scratch.p6.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 84fc650 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Namespace(adam=False, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='data/wesee.yaml', device='', entity=None, epochs=50, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp12', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='yolov7.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1     44944  models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "Model Summary: 415 layers, 37207344 parameters, 37207344 gradients, 105.1 GFLOPS\n",
      "\n",
      "Transferred 552/566 items from yolov7.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../../dataset/Wesee_parsed/train/labels' images and labels... 2\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../../dataset/Wesee_parsed/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../../dataset/Wesee_parsed/val/labels' images and labels... 3594 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../../dataset/Wesee_parsed/val/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.84, Best Possible Recall (BPR) = 0.9943\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/exp12\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      0/49       12G   0.04883   0.06547    0.0115    0.1258         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.599       0.769       0.717       0.442\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      1/49     21.8G   0.02723  0.004998  0.001004   0.03323        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.866       0.867        0.89       0.601\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      2/49     21.8G   0.02604  0.005049 0.0006747   0.03176         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.849       0.852       0.883       0.596\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      3/49     21.8G    0.0242  0.005009 0.0005872   0.02979        15       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.847       0.895       0.896       0.622\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      4/49     21.8G   0.02219   0.00473 0.0005381   0.02746         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.887       0.887       0.914       0.664\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      5/49     21.8G   0.02129  0.004635 0.0005049   0.02643         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.896       0.899       0.932       0.685\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      6/49     21.8G   0.02058  0.004522  0.000452   0.02555         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.886       0.918       0.932       0.695\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      7/49     21.8G   0.01984  0.004493 0.0004537   0.02479         3       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.887       0.923        0.93       0.698\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      8/49     21.8G   0.01958  0.004401 0.0004244    0.0244         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.868       0.924       0.926       0.709\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "      9/49     21.8G   0.01918  0.004379 0.0004403     0.024         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.896       0.925       0.935       0.715\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     10/49     21.8G   0.01884  0.004321 0.0004552   0.02362         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.883       0.933       0.946        0.73\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     11/49     21.8G   0.01851  0.004253  0.000422   0.02318         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.891       0.927       0.942       0.733\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     12/49     21.8G   0.01842  0.004223 0.0004408   0.02308         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.892       0.926       0.946       0.739\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     13/49     21.8G   0.01825  0.004206 0.0004158   0.02287         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.898       0.923       0.947       0.741\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     14/49     21.8G   0.01788   0.00411 0.0004123    0.0224         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.899        0.92       0.948       0.747\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     15/49     21.8G   0.01769  0.004148 0.0003909   0.02222         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.923       0.951       0.748\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     16/49     21.8G   0.01755  0.004114 0.0003898   0.02206        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030        0.88       0.947        0.95       0.754\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     17/49     21.8G   0.01731  0.004083 0.0004054    0.0218         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.915       0.912       0.945       0.754\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     18/49     21.8G   0.01711  0.004027 0.0003652   0.02151         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.899       0.934       0.952       0.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     19/49     21.8G     0.017   0.00399 0.0003641   0.02136         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.888        0.95       0.953       0.762\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     20/49     21.8G   0.01677   0.00398 0.0003738   0.02113        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.901       0.942       0.953       0.763\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     21/49     21.8G   0.01664  0.003997 0.0003508   0.02099        16       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.901       0.941       0.956       0.768\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     22/49     21.8G   0.01646  0.003908  0.000366   0.02074        10       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.909       0.937       0.955       0.768\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     23/49     21.8G   0.01634  0.003891 0.0003617   0.02059        14       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.902       0.943       0.955       0.769\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     24/49     21.8G    0.0161  0.003829 0.0003752   0.02031        12       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.911       0.934       0.957       0.773\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     25/49     21.8G   0.01599  0.003865 0.0003601   0.02022         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912       0.935       0.957       0.773\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     26/49     21.8G   0.01583  0.003837  0.000375   0.02004         4       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912       0.939       0.958       0.775\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     27/49     21.8G   0.01565  0.003842 0.0003649   0.01986         9       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.913       0.937       0.959       0.777\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     28/49     21.8G    0.0155  0.003796 0.0003445   0.01964        18       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.946        0.96       0.778\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     29/49     21.8G   0.01534  0.003747 0.0003413   0.01943         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.905       0.947        0.96       0.779\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     30/49     21.8G   0.01518  0.003674 0.0003498   0.01921         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912       0.941       0.961        0.78\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     31/49     21.8G   0.01496  0.003703 0.0003496   0.01901         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.912        0.94       0.958       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     32/49     21.8G   0.01486  0.003656 0.0003401   0.01885         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.909       0.948       0.961       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     33/49     21.8G    0.0147  0.003612 0.0003457   0.01866        13       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.913       0.943       0.961       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     34/49     21.8G   0.01455  0.003582 0.0003292   0.01846         3       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.906       0.949       0.962       0.781\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     35/49     21.8G   0.01447  0.003579 0.0003215   0.01837         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.953       0.961       0.783\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     36/49     21.8G   0.01436  0.003566 0.0003185   0.01824         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.904       0.954       0.962       0.783\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     37/49     21.8G    0.0142   0.00351 0.0003003   0.01801         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.918       0.938       0.963       0.784\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     38/49     21.8G   0.01409  0.003512 0.0002949   0.01789         6       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.919       0.938       0.962       0.786\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     39/49     21.8G   0.01394  0.003461 0.0003215   0.01772        15       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.921       0.938       0.962       0.786\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     40/49     21.8G   0.01382  0.003448 0.0003178   0.01758         7       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030        0.92       0.938       0.963       0.787\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     41/49     21.8G   0.01372  0.003407 0.0003004   0.01743         3       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.924       0.935       0.963       0.786\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     42/49     21.8G   0.01356  0.003406 0.0002991   0.01726         5       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.939       0.963       0.787\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     43/49     21.8G   0.01355  0.003379 0.0003117   0.01724        11       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.939       0.963       0.787\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     44/49     21.8G   0.01338  0.003332 0.0002897     0.017        11       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.939       0.964       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     45/49     21.8G   0.01331  0.003326 0.0002997   0.01693        13       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.923       0.938       0.963       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     46/49     21.8G   0.01326  0.003307 0.0003252   0.01689         2       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.923       0.938       0.963       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     47/49     21.8G   0.01328   0.00332 0.0003186   0.01692        13       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.924       0.937       0.963       0.789\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     48/49     21.8G   0.01327  0.003295 0.0002931   0.01686         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922       0.938       0.963       0.788\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "     49/49     21.8G   0.01315  0.003285 0.0003077   0.01674         9       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all        3594        5030       0.922        0.94       0.963       0.789\n",
      "         Zebra_Cross        3594        3619       0.981       0.962        0.99       0.938\n",
      "            R_Signal        3594        1021       0.885       0.937       0.954        0.72\n",
      "            G_Signal        3594         390         0.9        0.92       0.946       0.708\n",
      "50 epochs completed in 11.862 hours.\n",
      "\n",
      "Optimizer stripped from runs/train/exp12/weights/last.pt, 74.8MB\n",
      "Optimizer stripped from runs/train/exp12/weights/best.pt, 74.8MB\n"
     ]
    }
   ],
   "source": [
    "# Wesee Init Training\n",
    "!python train.py --batch-size 32 --epoch 50 --data data/wesee.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights yolov7.pt # --hyp data/hyp.scratch.p5.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/images/horses.jpg', update=False, view_img=False, weights=['yolov7.pt'])\n",
      "YOLOR ðŸš€ v0.1-79-gcc42a20 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to yolov7.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.1M/72.1M [00:06<00:00, 11.2MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients, 104.5 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      " The image with the result is saved in: runs/detect/exp/horses.jpg\n",
      "Done. (0.032s)\n"
     ]
    }
   ],
   "source": [
    "# My Inference test\n",
    "!python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.5, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/test', update=False, view_img=False, weights=['wesee.pt'])\n",
      "YOLOR ðŸš€ 84fc650 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      " The image with the result is saved in: runs/detect/exp4/MP_KSC_005400.jpg\n",
      " The image with the result is saved in: runs/detect/exp4/MP_KSC_005528.jpg\n",
      " The image with the result is saved in: runs/detect/exp4/MP_KSC_005529.jpg\n",
      "Done. (0.051s)\n"
     ]
    }
   ],
   "source": [
    "# Inference time test\n",
    "!python detect.py --weights wesee.pt --conf 0.5 --img-size 640 --source inference/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.3, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/sample', update=False, view_img=False, weights=['wesee.pt'])\n",
      "YOLOR ðŸš€ 72927ac torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n",
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_000328.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_000385.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_000684.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001103.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001131.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001142.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001244.jpg\n",
      " The image with the result is saved in: runs/detect/exp7/MP_KSC_001389.jpg\n",
      "Done. (0.127s)\n"
     ]
    }
   ],
   "source": [
    "# Inference time test\n",
    "!python detect.py --weights wesee.pt --conf 0.3 --img-size 640 --source inference/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d4ecf4a907e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./inference/images/horses.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mreslut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "model = torch.load(\"./wesee.pt\")\n",
    "path = './inference/images/horses.jpg'\n",
    "img = Image.open(path)\n",
    "result = model(img)\n",
    "reslut.print()\n",
    "result.pandas().xyxy[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Advanced Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_filter = ['train']\n",
    "opt  = {\n",
    "    \n",
    "    \"weights\": \"weights/yolov7.pt\", # Path to weights file default weights are for nano model\n",
    "    \"yaml\"   : \"data/coco.yaml\",\n",
    "    \"img-size\": 640, # default image size\n",
    "    \"conf-thres\": 0.25, # confidence threshold for inference.\n",
    "    \"iou-thres\" : 0.45, # NMS IoU threshold for inference.\n",
    "    \"device\" : '0',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
    "    \"classes\" : classes_to_filter  # list of classes to filter or None\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ v0.1-79-gcc42a20 torch 1.7.1+cu110 CUDA:0 (NVIDIA GeForce RTX 3090, 24265.3125MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to weights/yolov7.pt...\n",
      "Download error: [Errno 2] No such file or directory: 'weights/tmpnmoa1wca'\n",
      "ERROR: Download failure: weights/yolov7.pt missing, try downloading from https://github.com/WongKinYiu/yolov7/releases/\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weights/yolov7.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c65afd379094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mhalf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model stride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mimgsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_img_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check img_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MVP/yolov7/models/experimental.py\u001b[0m in \u001b[0;36mattempt_load\u001b[0;34m(weights, map_location)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mattempt_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ema'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ema'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights/yolov7.pt'"
     ]
    }
   ],
   "source": [
    "# Give path of source image\n",
    "source_image_path = 'inference/images/horses.jpg'\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  weights, imgsz = opt['weights'], opt['img-size']\n",
    "  set_logging()\n",
    "  device = select_device(opt['device'])\n",
    "  half = device.type != 'cpu'\n",
    "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "  stride = int(model.stride.max())  # model stride\n",
    "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "  if half:\n",
    "    model.half()\n",
    "\n",
    "  names = model.module.names if hasattr(model, 'module') else model.names\n",
    "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "  if device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "\n",
    "  img0 = cv2.imread(source_image_path)\n",
    "  img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "  img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "  img = np.ascontiguousarray(img)\n",
    "  img = torch.from_numpy(img).to(device)\n",
    "  img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "  img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "  if img.ndimension() == 3:\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "  # Inference\n",
    "  t1 = time_synchronized()\n",
    "  pred = model(img, augment= False)[0]\n",
    "\n",
    "  # Apply NMS\n",
    "  classes = None\n",
    "  if opt['classes']:\n",
    "    classes = []\n",
    "    for class_name in opt['classes']:\n",
    "\n",
    "      classes.append(names.index(class_name))\n",
    "\n",
    "  if classes:\n",
    "    \n",
    "    classes = [i for i in range(len(names)) if i not in classes]\n",
    "  \n",
    "  \n",
    "  pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= [17], agnostic= False)\n",
    "  t2 = time_synchronized()\n",
    "  for i, det in enumerate(pred):\n",
    "    s = ''\n",
    "    s += '%gx%g ' % img.shape[2:]  # print string\n",
    "    gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
    "    if len(det):\n",
    "      det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "\n",
    "      for c in det[:, -1].unique():\n",
    "        n = (det[:, -1] == c).sum()  # detections per class\n",
    "        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "    \n",
    "      for *xyxy, conf, cls in reversed(det):\n",
    "\n",
    "        label = f'{names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
